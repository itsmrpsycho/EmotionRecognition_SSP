{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './EmoDB_dataset/wav'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "def extract_mfcc_features(file_path: str, n_mfcc: int = 39, \n",
    "                          frame_size: float = 0.025, frame_stride: float = 0.01, \n",
    "                          n_segments: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts 39 MFCC features framewise from an audio file and then applies\n",
    "    average pooling to condense the features over time into an n x 39 feature matrix.\n",
    "    \n",
    "    Parameters:\n",
    "      file_path (str): Path to the audio file.\n",
    "      n_mfcc (int): Number of MFCC features to extract. Default is 39.\n",
    "      frame_size (float): Length of each frame in seconds. Default is 0.025.\n",
    "      frame_stride (float): Step between successive frames in seconds. Default is 0.01.\n",
    "      n_segments (int): Number of segments (n) to pool the frames into.\n",
    "    \n",
    "    Returns:\n",
    "      np.ndarray: A n x 39 array where each row is the average MFCC vector for that segment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signal, sample_rate = librosa.load(file_path, sr=None)\n",
    "        frame_length = int(frame_size * sample_rate)\n",
    "        hop_length = int(frame_stride * sample_rate)\n",
    "        \n",
    "        # Extract MFCC features; result shape is (n_mfcc, T) where T is number of frames.\n",
    "        mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=n_mfcc,\n",
    "                                    n_fft=frame_length, hop_length=hop_length)\n",
    "        \n",
    "        # Normalize the MFCC features along each coefficient dimension.\n",
    "        mfcc_normalized = mfcc - np.mean(mfcc, axis=1, keepdims=True)\n",
    "        \n",
    "        # Transpose to shape (T, n_mfcc) for pooling along the time axis.\n",
    "        mfcc_normalized = mfcc_normalized.T\n",
    "        \n",
    "        # Divide the frames into n_segments segments and compute the average for each segment.\n",
    "        segments = np.array_split(mfcc_normalized, n_segments, axis=0)\n",
    "        pooled_features = np.array([np.mean(seg, axis=0) for seg in segments])\n",
    "        \n",
    "        return pooled_features  # Shape: (n_segments, 39)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "    return np.array([])\n",
    "\n",
    "def process_directory_mfcc(directory: str, n_segments: int = 10) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Processes all .wav files in the given directory, extracting their MFCC features\n",
    "    using average pooling to produce an n x 39 feature matrix for each file.\n",
    "    \n",
    "    Parameters:\n",
    "      directory (str): Path to the directory containing .wav files.\n",
    "      n_segments (int): Number of segments to pool the frames into for each file.\n",
    "    \n",
    "    Returns:\n",
    "      Dict[str, np.ndarray]: A dictionary mapping filenames to their corresponding feature matrices.\n",
    "    \"\"\"\n",
    "    feature_vectors = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            features = extract_mfcc_features(file_path, n_segments=n_segments)\n",
    "            if features.size > 0:\n",
    "                feature_vectors[filename] = features\n",
    "    return feature_vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier on MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "def load_labels(csv_file: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(csv_file)\n",
    "\n",
    "def prepare_dataset(features: dict, labels: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Constructs the dataset by matching each audio file's feature matrix with its label.\n",
    "    Since each file is represented as an n x 39 matrix (n segments by 39 features),\n",
    "    we flatten it into a 1D feature vector of length n*39.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in labels.iterrows():\n",
    "        file_id = row['Filename']\n",
    "        if file_id in features:\n",
    "            # Flatten the (n, 39) matrix to a 1D vector (n*39,)\n",
    "            feature_matrix = features[file_id]\n",
    "            feature_vector = feature_matrix.flatten()\n",
    "            X.append(feature_vector)\n",
    "            y.append(int(row['EmotionNumeric']))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def train_and_evaluate(X, y, n):\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train GMM Classifier\n",
    "    gmm_model = GaussianMixture(n_components=len(np.unique(y)), random_state=42)\n",
    "    gmm_model.fit(X_train)\n",
    "    gmm_predictions = gmm_model.predict(X_test)\n",
    "\n",
    "    # Train SVM Classifier\n",
    "    svm_model = SVC(kernel='linear', random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    svm_predictions = svm_model.predict(X_test)\n",
    "\n",
    "    # Evaluate classifiers\n",
    "    gmm_accuracy = accuracy_score(y_test, gmm_predictions)\n",
    "    gmm_precision = precision_score(y_test, gmm_predictions, average='weighted', zero_division=0)\n",
    "    gmm_recall = recall_score(y_test, gmm_predictions, average='weighted', zero_division=0)\n",
    "    gmm_f1 = f1_score(y_test, gmm_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "    svm_precision = precision_score(y_test, svm_predictions, average='weighted', zero_division=0)\n",
    "    svm_recall = recall_score(y_test, svm_predictions, average='weighted', zero_division=0)\n",
    "    svm_f1 = f1_score(y_test, svm_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    print(\"GMM Classifier Report:\")\n",
    "    print(classification_report(y_test, gmm_predictions))\n",
    "\n",
    "    print(\"SVM Classifier Report:\")\n",
    "    print(classification_report(y_test, svm_predictions))\n",
    "\n",
    "    # Log metrics to wandb\n",
    "    wandb.log({\n",
    "        \"n_segments\": n,\n",
    "        \"GMM Accuracy\": gmm_accuracy,\n",
    "        \"GMM Precision\": gmm_precision,\n",
    "        \"GMM Recall\": gmm_recall,\n",
    "        \"GMM F1 Score\": gmm_f1,\n",
    "        \"SVM Accuracy\": svm_accuracy,\n",
    "        \"SVM Precision\": svm_precision,\n",
    "        \"SVM Recall\": svm_recall,\n",
    "        \"SVM F1 Score\": svm_f1\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\College\\4-2\\SSP\\SSP_Project\\newProject\\EmotionRecognition_SSP\\wandb\\run-20250421_221529-odvamt1q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/odvamt1q' target=\"_blank\">ssp-mfcc-classification</a></strong> to <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/odvamt1q' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/odvamt1q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for n_segments = 5\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 195)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.21      0.90      0.34        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.20      0.07      0.11        14\n",
      "           4       0.20      0.17      0.18        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.21       107\n",
      "   macro avg       0.09      0.16      0.09       107\n",
      "weighted avg       0.10      0.21      0.11       107\n",
      "\n",
      "SVM Classifier Report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.83      0.59        18\n",
      "           1       0.71      0.75      0.73        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.62      0.36      0.45        14\n",
      "           4       0.71      0.56      0.62        18\n",
      "           5       0.50      0.44      0.47         9\n",
      "           6       0.44      0.44      0.44        16\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.49      0.48      0.47       107\n",
      "weighted avg       0.52      0.52      0.51       107\n",
      "\n",
      "\n",
      "Running for n_segments = 10\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 390)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.06      0.10        18\n",
      "           1       0.11      0.10      0.10        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.16      0.64      0.25        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.28      0.56      0.37         9\n",
      "           6       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.19       107\n",
      "   macro avg       0.28      0.22      0.17       107\n",
      "weighted avg       0.28      0.19      0.15       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.67      0.56        18\n",
      "           1       0.75      0.60      0.67        20\n",
      "           2       0.50      0.25      0.33        12\n",
      "           3       0.38      0.43      0.40        14\n",
      "           4       0.69      0.61      0.65        18\n",
      "           5       0.62      0.89      0.73         9\n",
      "           6       0.53      0.50      0.52        16\n",
      "\n",
      "    accuracy                           0.56       107\n",
      "   macro avg       0.56      0.56      0.55       107\n",
      "weighted avg       0.57      0.56      0.56       107\n",
      "\n",
      "\n",
      "Running for n_segments = 15\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 585)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.17      0.18        18\n",
      "           1       0.29      0.30      0.29        20\n",
      "           2       0.25      0.17      0.20        12\n",
      "           3       0.21      0.21      0.21        14\n",
      "           4       0.20      0.39      0.26        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.20       107\n",
      "   macro avg       0.16      0.18      0.16       107\n",
      "weighted avg       0.17      0.20      0.18       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.72      0.57        18\n",
      "           1       0.75      0.60      0.67        20\n",
      "           2       0.67      0.17      0.27        12\n",
      "           3       0.36      0.36      0.36        14\n",
      "           4       0.53      0.50      0.51        18\n",
      "           5       0.46      0.67      0.55         9\n",
      "           6       0.50      0.50      0.50        16\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.50      0.49       107\n",
      "weighted avg       0.54      0.51      0.50       107\n",
      "\n",
      "\n",
      "Running for n_segments = 20\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 780)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17        18\n",
      "           1       0.13      0.10      0.11        20\n",
      "           2       0.22      0.17      0.19        12\n",
      "           3       0.14      0.07      0.10        14\n",
      "           4       0.17      0.61      0.27        18\n",
      "           5       0.67      0.22      0.33         9\n",
      "           6       0.25      0.06      0.10        16\n",
      "\n",
      "    accuracy                           0.20       107\n",
      "   macro avg       0.27      0.19      0.18       107\n",
      "weighted avg       0.25      0.20      0.17       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.61      0.46        18\n",
      "           1       0.63      0.60      0.62        20\n",
      "           2       0.40      0.17      0.24        12\n",
      "           3       0.36      0.36      0.36        14\n",
      "           4       0.42      0.28      0.33        18\n",
      "           5       0.56      0.56      0.56         9\n",
      "           6       0.44      0.50      0.47        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.45      0.44      0.43       107\n",
      "weighted avg       0.45      0.45      0.44       107\n",
      "\n",
      "\n",
      "Running for n_segments = 25\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 975)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.11      0.14        18\n",
      "           1       0.33      0.10      0.15        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.13      0.50      0.20        14\n",
      "           4       0.17      0.22      0.19        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.33      0.06      0.11        16\n",
      "\n",
      "    accuracy                           0.15       107\n",
      "   macro avg       0.17      0.14      0.11       107\n",
      "weighted avg       0.19      0.15      0.13       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.50      0.45        18\n",
      "           1       0.71      0.60      0.65        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.27      0.43      0.33        14\n",
      "           4       0.47      0.44      0.46        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.47      0.44      0.45        16\n",
      "\n",
      "    accuracy                           0.46       107\n",
      "   macro avg       0.42      0.46      0.43       107\n",
      "weighted avg       0.43      0.46      0.44       107\n",
      "\n",
      "\n",
      "Running for n_segments = 30\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 1170)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.06      0.10        18\n",
      "           1       0.25      0.20      0.22        20\n",
      "           2       0.12      0.50      0.19        12\n",
      "           3       0.12      0.14      0.13        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.12       107\n",
      "   macro avg       0.12      0.13      0.09       107\n",
      "weighted avg       0.13      0.12      0.10       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.83      0.60        18\n",
      "           1       0.91      0.50      0.65        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.29      0.36      0.32        14\n",
      "           4       0.60      0.33      0.43        18\n",
      "           5       0.47      0.78      0.58         9\n",
      "           6       0.55      0.69      0.61        16\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.54      0.51      0.48       107\n",
      "weighted avg       0.57      0.51      0.49       107\n",
      "\n",
      "\n",
      "Running for n_segments = 35\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 1365)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.06      0.08        18\n",
      "           1       0.09      0.05      0.06        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.13      0.64      0.21        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.33      0.12      0.18        16\n",
      "\n",
      "    accuracy                           0.12       107\n",
      "   macro avg       0.10      0.12      0.08       107\n",
      "weighted avg       0.11      0.12      0.08       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.67      0.50        18\n",
      "           1       0.56      0.45      0.50        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.36      0.29      0.32        14\n",
      "           4       0.44      0.39      0.41        18\n",
      "           5       0.67      0.89      0.76         9\n",
      "           6       0.47      0.56      0.51        16\n",
      "\n",
      "    accuracy                           0.47       107\n",
      "   macro avg       0.46      0.48      0.45       107\n",
      "weighted avg       0.46      0.47      0.44       107\n",
      "\n",
      "\n",
      "Running for n_segments = 40\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 1560)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17        18\n",
      "           1       0.11      0.05      0.07        20\n",
      "           2       0.20      0.67      0.30        12\n",
      "           3       0.15      0.21      0.18        14\n",
      "           4       0.08      0.06      0.07        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.14       107\n",
      "   macro avg       0.12      0.16      0.11       107\n",
      "weighted avg       0.13      0.14      0.11       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.61      0.52        18\n",
      "           1       0.64      0.45      0.53        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.37      0.50      0.42        14\n",
      "           4       0.47      0.44      0.46        18\n",
      "           5       0.50      0.67      0.57         9\n",
      "           6       0.32      0.38      0.34        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.47      0.45      0.43       107\n",
      "weighted avg       0.47      0.45      0.43       107\n",
      "\n",
      "\n",
      "Running for n_segments = 45\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 1755)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17        18\n",
      "           1       1.00      0.05      0.10        20\n",
      "           2       0.12      0.83      0.22        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.67      0.12      0.21        16\n",
      "\n",
      "    accuracy                           0.14       107\n",
      "   macro avg       0.30      0.16      0.10       107\n",
      "weighted avg       0.36      0.14      0.10       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59        18\n",
      "           1       0.73      0.55      0.63        20\n",
      "           2       0.29      0.17      0.21        12\n",
      "           3       0.33      0.36      0.34        14\n",
      "           4       0.47      0.39      0.42        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.47      0.50      0.48        16\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.48      0.49      0.48       107\n",
      "weighted avg       0.49      0.50      0.49       107\n",
      "\n",
      "\n",
      "Running for n_segments = 50\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 1950)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.11      0.05      0.07        20\n",
      "           2       0.05      0.08      0.06        12\n",
      "           3       0.10      0.14      0.11        14\n",
      "           4       0.07      0.06      0.06        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.05       107\n",
      "   macro avg       0.05      0.05      0.04       107\n",
      "weighted avg       0.05      0.05      0.05       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.61      0.47        18\n",
      "           1       0.56      0.45      0.50        20\n",
      "           2       0.33      0.17      0.22        12\n",
      "           3       0.25      0.14      0.18        14\n",
      "           4       0.27      0.17      0.21        18\n",
      "           5       0.50      0.89      0.64         9\n",
      "           6       0.38      0.50      0.43        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.38      0.42      0.38       107\n",
      "weighted avg       0.38      0.40      0.37       107\n",
      "\n",
      "\n",
      "Running for n_segments = 55\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 2145)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.11      0.16        18\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.17      0.58      0.26        12\n",
      "           3       0.22      0.14      0.17        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.14      0.25      0.18        16\n",
      "\n",
      "    accuracy                           0.14       107\n",
      "   macro avg       0.12      0.16      0.11       107\n",
      "weighted avg       0.12      0.14      0.11       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.44      0.35        18\n",
      "           1       0.50      0.45      0.47        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.36      0.36      0.36        14\n",
      "           4       0.55      0.33      0.41        18\n",
      "           5       0.47      0.89      0.62         9\n",
      "           6       0.40      0.38      0.39        16\n",
      "\n",
      "    accuracy                           0.39       107\n",
      "   macro avg       0.37      0.41      0.37       107\n",
      "weighted avg       0.38      0.39      0.37       107\n",
      "\n",
      "\n",
      "Running for n_segments = 60\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 2340)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.12      0.10      0.11        20\n",
      "           2       0.17      0.58      0.27        12\n",
      "           3       0.11      0.07      0.09        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.25      0.33      0.29         9\n",
      "           6       0.36      0.31      0.33        16\n",
      "\n",
      "    accuracy                           0.17       107\n",
      "   macro avg       0.15      0.20      0.16       107\n",
      "weighted avg       0.13      0.17      0.14       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69        18\n",
      "           1       0.62      0.40      0.48        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.25      0.14      0.18        14\n",
      "           4       0.56      0.50      0.53        18\n",
      "           5       0.57      0.89      0.70         9\n",
      "           6       0.33      0.38      0.35        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.44      0.48      0.44       107\n",
      "weighted avg       0.46      0.49      0.45       107\n",
      "\n",
      "\n",
      "Running for n_segments = 65\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 2535)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.06      0.08        18\n",
      "           1       0.21      0.20      0.21        20\n",
      "           2       0.14      0.58      0.22        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.11       107\n",
      "   macro avg       0.07      0.12      0.07       107\n",
      "weighted avg       0.08      0.11      0.08       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.50      0.44        18\n",
      "           1       0.62      0.50      0.56        20\n",
      "           2       0.33      0.17      0.22        12\n",
      "           3       0.25      0.29      0.27        14\n",
      "           4       0.44      0.39      0.41        18\n",
      "           5       0.73      0.89      0.80         9\n",
      "           6       0.21      0.25      0.23        16\n",
      "\n",
      "    accuracy                           0.41       107\n",
      "   macro avg       0.42      0.43      0.42       107\n",
      "weighted avg       0.42      0.41      0.41       107\n",
      "\n",
      "\n",
      "Running for n_segments = 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files processed: 535\n",
      "Dataset shape: (535, 2730)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.22      0.18        18\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.12      0.33      0.18        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.12      0.06      0.08        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.13      0.19      0.15        16\n",
      "\n",
      "    accuracy                           0.11       107\n",
      "   macro avg       0.07      0.11      0.08       107\n",
      "weighted avg       0.08      0.11      0.09       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.67      0.55        18\n",
      "           1       0.57      0.65      0.60        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.29      0.29      0.29        14\n",
      "           4       0.50      0.33      0.40        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.44      0.50      0.47        16\n",
      "\n",
      "    accuracy                           0.48       107\n",
      "   macro avg       0.48      0.47      0.45       107\n",
      "weighted avg       0.48      0.48      0.45       107\n",
      "\n",
      "\n",
      "Running for n_segments = 75\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 2925)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.14      0.15      0.14        20\n",
      "           2       0.15      0.92      0.26        12\n",
      "           3       0.25      0.07      0.11        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.14       107\n",
      "   macro avg       0.08      0.16      0.07       107\n",
      "weighted avg       0.08      0.14      0.07       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      1.00      0.63        18\n",
      "           1       0.57      0.40      0.47        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.43      0.21      0.29        14\n",
      "           4       0.38      0.17      0.23        18\n",
      "           5       0.53      1.00      0.69         9\n",
      "           6       0.37      0.44      0.40        16\n",
      "\n",
      "    accuracy                           0.46       107\n",
      "   macro avg       0.44      0.47      0.41       107\n",
      "weighted avg       0.44      0.46      0.40       107\n",
      "\n",
      "\n",
      "Running for n_segments = 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files processed: 535\n",
      "Dataset shape: (535, 3120)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.06      0.07        18\n",
      "           1       0.36      0.25      0.29        20\n",
      "           2       0.25      0.17      0.20        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.18      0.44      0.26         9\n",
      "           6       0.21      0.56      0.31        16\n",
      "\n",
      "    accuracy                           0.20       107\n",
      "   macro avg       0.15      0.21      0.16       107\n",
      "weighted avg       0.16      0.20      0.16       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.67      0.55        18\n",
      "           1       0.65      0.55      0.59        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.40      0.29      0.33        14\n",
      "           4       0.43      0.33      0.38        18\n",
      "           5       0.60      1.00      0.75         9\n",
      "           6       0.42      0.62      0.50        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.42      0.49      0.44       107\n",
      "weighted avg       0.44      0.49      0.45       107\n",
      "\n",
      "\n",
      "Running for n_segments = 85\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 3315)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.11      0.25      0.15        12\n",
      "           3       0.15      0.21      0.18        14\n",
      "           4       0.06      0.06      0.06        18\n",
      "           5       0.09      0.22      0.12         9\n",
      "           6       0.15      0.12      0.14        16\n",
      "\n",
      "    accuracy                           0.10       107\n",
      "   macro avg       0.08      0.12      0.09       107\n",
      "weighted avg       0.07      0.10      0.08       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.78      0.60        18\n",
      "           1       0.75      0.60      0.67        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.33      0.29      0.31        14\n",
      "           4       0.67      0.56      0.61        18\n",
      "           5       0.50      1.00      0.67         9\n",
      "           6       0.60      0.56      0.58        16\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.55      0.55      0.51       107\n",
      "weighted avg       0.57      0.55      0.53       107\n",
      "\n",
      "\n",
      "Running for n_segments = 90\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 3510)\n",
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.11      0.13        18\n",
      "           1       1.00      0.05      0.10        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.11      0.14      0.12        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.03      0.11      0.04         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.06       107\n",
      "   macro avg       0.18      0.06      0.06       107\n",
      "weighted avg       0.23      0.06      0.06       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.39      0.42        18\n",
      "           1       0.62      0.40      0.48        20\n",
      "           2       0.09      0.08      0.09        12\n",
      "           3       0.42      0.57      0.48        14\n",
      "           4       0.53      0.50      0.51        18\n",
      "           5       0.50      0.78      0.61         9\n",
      "           6       0.33      0.38      0.35        16\n",
      "\n",
      "    accuracy                           0.43       107\n",
      "   macro avg       0.42      0.44      0.42       107\n",
      "weighted avg       0.44      0.43      0.43       107\n",
      "\n",
      "\n",
      "Running for n_segments = 95\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 3705)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GMM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.17      0.17        18\n",
      "           1       0.39      0.35      0.37        20\n",
      "           2       0.18      0.17      0.17        12\n",
      "           3       0.15      0.29      0.20        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.00      0.00      0.00        16\n",
      "\n",
      "    accuracy                           0.15       107\n",
      "   macro avg       0.13      0.14      0.13       107\n",
      "weighted avg       0.14      0.15      0.14       107\n",
      "\n",
      "SVM Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.61      0.52        18\n",
      "           1       0.60      0.60      0.60        20\n",
      "           2       0.40      0.17      0.24        12\n",
      "           3       0.31      0.36      0.33        14\n",
      "           4       0.43      0.33      0.38        18\n",
      "           5       0.54      0.78      0.64         9\n",
      "           6       0.33      0.31      0.32        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.44      0.45      0.43       107\n",
      "weighted avg       0.44      0.45      0.44       107\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>GMM Accuracy</td><td>█▇██▆▄▄▅▅▁▅▆▄▄▅█▃▁▆</td></tr><tr><td>GMM F1 Score</td><td>▄▆██▅▄▃▄▄▁▄▆▃▃▂▇▃▂▆</td></tr><tr><td>GMM Precision</td><td>▂▆▄▆▄▃▂▃█▁▃▃▂▂▂▃▂▅▃</td></tr><tr><td>GMM Recall</td><td>█▇██▆▄▄▅▅▁▅▆▄▄▅█▃▁▆</td></tr><tr><td>SVM Accuracy</td><td>▆█▆▃▄▆▄▃▅▁▁▅▂▄▄▅█▃▃</td></tr><tr><td>SVM F1 Score</td><td>▆█▆▄▄▆▄▃▅▁▁▄▂▄▂▄▇▃▃</td></tr><tr><td>SVM Precision</td><td>▆█▇▄▃█▄▄▅▁▁▄▂▅▃▃█▃▃</td></tr><tr><td>SVM Recall</td><td>▆█▆▃▄▆▄▃▅▁▁▅▂▄▄▅█▃▃</td></tr><tr><td>n_segments</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GMM Accuracy</td><td>0.14953</td></tr><tr><td>GMM F1 Score</td><td>0.14257</td></tr><tr><td>GMM Precision</td><td>0.14125</td></tr><tr><td>GMM Recall</td><td>0.14953</td></tr><tr><td>SVM Accuracy</td><td>0.4486</td></tr><tr><td>SVM F1 Score</td><td>0.43512</td></tr><tr><td>SVM Precision</td><td>0.44223</td></tr><tr><td>SVM Recall</td><td>0.4486</td></tr><tr><td>n_segments</td><td>95</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-mfcc-classification</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/odvamt1q' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/odvamt1q</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_221529-odvamt1q\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"emotion-recognition\", name=\"ssp-mfcc-classification\")\n",
    "\n",
    "# Example usage: Varying n\n",
    "n_values = np.arange(5, 100, 5)  # n_segments from 5 to 20 in steps of 5\n",
    "labels_csv_path = \"EmoDB_dataset/emotion_mapping_detailed.csv\"\n",
    "labels = load_labels(labels_csv_path)\n",
    "\n",
    "for n in n_values:\n",
    "    print(f\"\\nRunning for n_segments = {n}\")\n",
    "    \n",
    "    # Extract MFCC features with the current n\n",
    "    mfccFeatures = process_directory_mfcc(directory, n)\n",
    "    print(f\"Number of files processed: {len(mfccFeatures)}\")\n",
    "    \n",
    "    # Prepare the dataset: each feature matrix is flattened to become a vector\n",
    "    X, y = prepare_dataset(mfccFeatures, labels)\n",
    "    print(\"Dataset shape:\", X.shape)\n",
    "    \n",
    "    # Train and evaluate classifiers, logging metrics to wandb\n",
    "    train_and_evaluate(X, y, n)\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCC and LP Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import lfilter\n",
    "from scipy.fftpack import dct\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "def extract_rcc(frame: np.ndarray, order: int = 12, n_rcc: int = 12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract Residual Cepstral Coefficients (RCC) from a signal frame using LPC and residual signal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: LPC Analysis - Calculate the LPC coefficients (Prediction Coefficients)\n",
    "        autocorr = np.correlate(frame, frame, mode='full')\n",
    "        autocorr = autocorr[len(autocorr)//2:]  # Keep second half (autocorrelation)\n",
    "        \n",
    "        if autocorr[0] == 0:\n",
    "            return np.zeros(n_rcc)  # Silent frame, return zero vector\n",
    "        \n",
    "        # Levinson-Durbin recursion to solve for LPC coefficients\n",
    "        a = np.zeros(order + 1)\n",
    "        e = autocorr[0]\n",
    "        k = np.zeros(order)\n",
    "\n",
    "        for i in range(order):\n",
    "            acc = autocorr[i + 1] - np.dot(a[1:i + 1], autocorr[i:0:-1])\n",
    "            ki = acc / e\n",
    "            k[i] = ki\n",
    "            a[1:i+1] -= ki * a[i:0:-1]\n",
    "            a[i + 1] = ki\n",
    "            e *= (1 - ki ** 2)\n",
    "\n",
    "        # Step 2: Compute the residual signal by filtering the frame using LPC coefficients\n",
    "        residual = lfilter(a, [1.0], frame)\n",
    "        \n",
    "        # Step 3: Apply Cepstral Analysis (DCT) to the residual signal\n",
    "        # We use the first n_rcc coefficients from the DCT of the log of the residual power spectrum\n",
    "        residual_power_spectrum = np.abs(np.fft.fft(residual)) ** 2\n",
    "        log_residual_spectrum = np.log(residual_power_spectrum + 1e-8)  # Log power spectrum\n",
    "\n",
    "        # Compute the DCT (Discrete Cosine Transform)\n",
    "        rcc = dct(log_residual_spectrum, type=2)[:n_rcc]\n",
    "        \n",
    "        return rcc\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting RCC: {e}\")\n",
    "        return np.zeros(n_rcc)  # Return zero vector in case of error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def compute_lp_residual_energy(frame: np.ndarray, order: int = 12) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Linear Prediction (LP) residual energy of a signal frame using librosa.\n",
    "\n",
    "    Parameters:\n",
    "    frame (np.ndarray): The input frame of the signal.\n",
    "    order (int): The order of the LPC analysis (default is 12).\n",
    "\n",
    "    Returns:\n",
    "    float: The energy of the LP residual signal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: LPC Analysis using librosa to compute LPC coefficients\n",
    "        a = librosa.lpc(frame, order=order)  # LPC coefficients (a[0] is the gain)\n",
    "\n",
    "        # Step 2: Compute the residual signal by filtering the frame using LPC coefficients\n",
    "        residual = lfilter(a, [1.0], frame)\n",
    "\n",
    "        # Step 3: Compute the energy of the residual signal (sum of squared values)\n",
    "        residual_energy = np.sum(residual ** 2)\n",
    "\n",
    "        return residual_energy\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing LP residual energy: {e}\")\n",
    "        return 0.0  # Return zero in case of error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import lfilter\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "def extract_rcc_lp_features(file_path: str,\n",
    "                            frame_size: float = 0.025,\n",
    "                            frame_stride: float = 0.01,\n",
    "                            target_rcc_segments: int = 100,\n",
    "                            target_lp_segments: int = 100,\n",
    "                            rcc_order: int = 12) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts RCC and LP residual energy framewise then condenses the features \n",
    "    into fixed-length feature matrices via average pooling.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        frame_size (float): Frame duration in seconds.\n",
    "        frame_stride (float): Step between successive frames in seconds.\n",
    "        target_rcc_segments (int): Desired number of pooled segments for RCC features.\n",
    "        target_lp_segments (int): Desired number of pooled segments for LP residual features.\n",
    "        rcc_order (int): Number of RCC coefficients to extract per frame.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            np.ndarray: Pooled RCC features with shape (target_rcc_segments, rcc_order).\n",
    "            np.ndarray: Pooled LP residual energies with shape (target_lp_segments, 1).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signal, sr = librosa.load(file_path, sr=None)\n",
    "        frame_length = int(frame_size * sr)\n",
    "        hop_length = int(frame_stride * sr)\n",
    "        \n",
    "        # Frame the signal: shape (number_of_frames, frame_length)\n",
    "        frames = librosa.util.frame(signal, frame_length=frame_length, hop_length=hop_length).T\n",
    "\n",
    "        rcc_list = []\n",
    "        lp_list = []\n",
    "        \n",
    "        for frame in frames:\n",
    "            # Apply windowing\n",
    "            frame = frame * np.hamming(len(frame))\n",
    "            \n",
    "            # RCC extraction: use LPC analysis then DCT of the log power spectrum\n",
    "            # (using the existing extract_rcc logic)\n",
    "            try:\n",
    "                # Compute autocorrelation for LPC\n",
    "                autocorr = np.correlate(frame, frame, mode='full')\n",
    "                autocorr = autocorr[len(autocorr)//2:]\n",
    "                if autocorr[0] == 0:\n",
    "                    rcc = np.zeros(rcc_order)\n",
    "                else:\n",
    "                    a = np.zeros(rcc_order + 1)\n",
    "                    e = autocorr[0]\n",
    "                    for i in range(rcc_order):\n",
    "                        acc = autocorr[i + 1] - np.dot(a[1:i+1], autocorr[i:0:-1])\n",
    "                        ki = acc / e\n",
    "                        a[1:i+1] -= ki * a[i:0:-1]\n",
    "                        a[i + 1] = ki\n",
    "                        e *= (1 - ki ** 2)\n",
    "                    # Residual signal\n",
    "                    residual = lfilter(a, [1.0], frame)\n",
    "                    # Compute RCC using DCT\n",
    "                    residual_power_spectrum = np.abs(np.fft.fft(residual)) ** 2\n",
    "                    log_residual_spectrum = np.log(residual_power_spectrum + 1e-8)\n",
    "                    rcc = dct(log_residual_spectrum, type=2)[:rcc_order]\n",
    "            except Exception as ex:\n",
    "                print(f\"Error in RCC extraction for frame: {ex}\")\n",
    "                rcc = np.zeros(rcc_order)\n",
    "            \n",
    "            # LP residual energy extraction: using librosa.lpc for LPC coefficients\n",
    "            try:\n",
    "                a_lp = librosa.lpc(frame, order=rcc_order) \n",
    "                residual_lp = lfilter(a_lp, [1.0], frame)\n",
    "                lp_energy = np.sum(residual_lp ** 2)\n",
    "            except Exception as ex:\n",
    "                print(f\"Error in LP energy computation for frame: {ex}\")\n",
    "                lp_energy = 0.0\n",
    "            \n",
    "            rcc_list.append(rcc)\n",
    "            lp_list.append([lp_energy])  # Keep as list for 2D array\n",
    "\n",
    "        rcc_array = np.array(rcc_list)  # shape: (num_frames, rcc_order)\n",
    "        lp_array = np.array(lp_list)      # shape: (num_frames, 1)\n",
    "        \n",
    "        # Average pool features to desired length for each feature type\n",
    "        # For RCC features\n",
    "        rcc_segments = np.array_split(rcc_array, target_rcc_segments, axis=0)\n",
    "        rcc_pooled = np.array([np.mean(seg, axis=0) for seg in rcc_segments])\n",
    "        \n",
    "        # For LP residual energy features\n",
    "        lp_segments = np.array_split(lp_array, target_lp_segments, axis=0)\n",
    "        lp_pooled = np.array([np.mean(seg, axis=0) for seg in lp_segments])\n",
    "        \n",
    "        return rcc_pooled, lp_pooled\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return np.zeros((target_rcc_segments, rcc_order)), np.zeros((target_lp_segments, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory_rcc_lp(directory: str,\n",
    "                             frame_size: float = 0.025,\n",
    "                             frame_stride: float = 0.01,\n",
    "                             target_rcc_segments: int = 100,\n",
    "                             target_lp_segments: int = 100,\n",
    "                             rcc_order: int = 12) -> dict:\n",
    "    \"\"\"\n",
    "    Processes all .wav files in the directory and extracts RCC and LP residual features.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing .wav files.\n",
    "        frame_size (float): Frame duration in seconds.\n",
    "        frame_stride (float): Step between successive frames in seconds.\n",
    "        target_rcc_segments (int): Desired number of pooled segments for RCC features.\n",
    "        target_lp_segments (int): Desired number of pooled segments for LP residual features.\n",
    "        rcc_order (int): Number of RCC coefficients to extract per frame.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of filename to {\"RCC\": <flattened RCC vector>,\n",
    "                                      \"LP\": <flattened LP vector>,\n",
    "                                      \"Full\": <concatenated RCC and LP features>}.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import numpy as np\n",
    "\n",
    "    feature_vectors = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            rcc, lp = extract_rcc_lp_features(\n",
    "                file_path,\n",
    "                frame_size=frame_size,\n",
    "                frame_stride=frame_stride,\n",
    "                target_rcc_segments=target_rcc_segments,\n",
    "                target_lp_segments=target_lp_segments,\n",
    "                rcc_order=rcc_order\n",
    "            )\n",
    "            rcc_flat = rcc.flatten()  # Shape: (target_rcc_segments * rcc_order,)\n",
    "            lp_flat = lp.flatten()    # Shape: (target_lp_segments,)\n",
    "\n",
    "            feature_vectors[filename] = {\n",
    "                \"RCC\": rcc_flat,\n",
    "                \"LP\": lp_flat,\n",
    "                \"Full\": np.concatenate([rcc_flat, lp_flat])\n",
    "            }\n",
    "\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(features: dict, labels: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prepares RCC, LP, and combined feature sets for classification.\n",
    "\n",
    "    Returns:\n",
    "        X_full (np.ndarray): RCC + LP.\n",
    "        X_rcc (np.ndarray): RCC only.\n",
    "        X_lp (np.ndarray): LP only.\n",
    "        y (np.ndarray): Emotion labels.\n",
    "    \"\"\"\n",
    "    X_full, X_rcc, X_lp, y = [], [], [], []\n",
    "\n",
    "    for _, row in labels.iterrows():\n",
    "        file_id = row['Filename']\n",
    "        if file_id in features:\n",
    "            feat = features[file_id]\n",
    "            X_full.append(feat[\"Full\"])\n",
    "            X_rcc.append(feat[\"RCC\"])\n",
    "            X_lp.append(feat[\"LP\"])\n",
    "            y.append(int(row['EmotionNumeric']))\n",
    "\n",
    "    return (\n",
    "        np.array(X_full),\n",
    "        np.array(X_rcc),\n",
    "        np.array(X_lp),\n",
    "        np.array(y)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "def train_and_evaluate(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple classifiers: SVM, Random Forest, XGBoost, Logistic Regression, KNN.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM (Linear Kernel)\": SVC(kernel='linear', random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=20000, random_state=42),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\nTraining and evaluating: {name}\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full (RCC + LP) shape: (535, 240)\n",
      "RCC-only shape: (535, 120)\n",
      "LP-only shape: (535, 120)\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "directory = \"./EmoDB_dataset/wav\"  # Replace with your path\n",
    "labels_csv_path = \"./EmoDB_dataset/emotion_mapping_detailed.csv\"  # Replace with your CSV path\n",
    "\n",
    "# Load label CSV\n",
    "labels = pd.read_csv(labels_csv_path)\n",
    "\n",
    "# Extract RCC and LP features\n",
    "features = process_directory_rcc_lp(directory, target_rcc_segments = 10, target_lp_segments = 120)\n",
    "\n",
    "# Prepare feature sets\n",
    "X_full, X_rcc, X_lp, y = prepare_dataset(features, labels)\n",
    "\n",
    "# Check dataset shapes\n",
    "print(\"Full (RCC + LP) shape:\", X_full.shape)\n",
    "print(\"RCC-only shape:\", X_rcc.shape)\n",
    "print(\"LP-only shape:\", X_lp.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RCC + LP Residual ---\n",
      "\n",
      "Training and evaluating: SVM (Linear Kernel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65        18\n",
      "           1       0.67      0.50      0.57        20\n",
      "           2       0.43      0.25      0.32        12\n",
      "           3       0.47      0.64      0.55        14\n",
      "           4       0.59      0.56      0.57        18\n",
      "           5       0.56      0.56      0.56         9\n",
      "           6       0.57      0.75      0.65        16\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.56      0.56      0.55       107\n",
      "weighted avg       0.57      0.57      0.56       107\n",
      "\n",
      "\n",
      "Training and evaluating: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.89      0.68        18\n",
      "           1       0.80      0.60      0.69        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.43      0.46        14\n",
      "           4       0.47      0.39      0.42        18\n",
      "           5       0.69      1.00      0.82         9\n",
      "           6       0.52      0.75      0.62        16\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.50      0.58      0.53       107\n",
      "weighted avg       0.52      0.58      0.54       107\n",
      "\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.89      0.73        18\n",
      "           1       0.67      0.40      0.50        20\n",
      "           2       0.43      0.25      0.32        12\n",
      "           3       0.58      0.50      0.54        14\n",
      "           4       0.53      0.50      0.51        18\n",
      "           5       0.69      1.00      0.82         9\n",
      "           6       0.55      0.69      0.61        16\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.58      0.60      0.58       107\n",
      "weighted avg       0.58      0.59      0.57       107\n",
      "\n",
      "\n",
      "Training and evaluating: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60        18\n",
      "           1       0.56      0.45      0.50        20\n",
      "           2       0.18      0.17      0.17        12\n",
      "           3       0.32      0.43      0.36        14\n",
      "           4       0.50      0.44      0.47        18\n",
      "           5       0.64      0.78      0.70         9\n",
      "           6       0.50      0.69      0.58        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.49      0.49      0.48       107\n",
      "weighted avg       0.51      0.49      0.49       107\n",
      "\n",
      "\n",
      "Training and evaluating: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.78      0.55        18\n",
      "           1       0.35      0.55      0.43        20\n",
      "           2       0.40      0.17      0.24        12\n",
      "           3       0.57      0.29      0.38        14\n",
      "           4       0.33      0.11      0.17        18\n",
      "           5       0.80      0.44      0.57         9\n",
      "           6       0.30      0.38      0.33        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.45      0.39      0.38       107\n",
      "weighted avg       0.43      0.40      0.38       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- RCC + LP Residual ---\")\n",
    "train_and_evaluate(X_full, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RCC Only ---\n",
      "\n",
      "Training and evaluating: SVM (Linear Kernel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65        18\n",
      "           1       0.67      0.50      0.57        20\n",
      "           2       0.43      0.25      0.32        12\n",
      "           3       0.47      0.64      0.55        14\n",
      "           4       0.59      0.56      0.57        18\n",
      "           5       0.56      0.56      0.56         9\n",
      "           6       0.57      0.75      0.65        16\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.56      0.56      0.55       107\n",
      "weighted avg       0.57      0.57      0.56       107\n",
      "\n",
      "\n",
      "Training and evaluating: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.89      0.64        18\n",
      "           1       0.59      0.65      0.62        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.45      0.36      0.40        14\n",
      "           4       0.75      0.50      0.60        18\n",
      "           5       0.75      1.00      0.86         9\n",
      "           6       0.38      0.38      0.38        16\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.56      0.55      0.52       107\n",
      "weighted avg       0.56      0.55      0.52       107\n",
      "\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67        18\n",
      "           1       0.67      0.50      0.57        20\n",
      "           2       0.33      0.25      0.29        12\n",
      "           3       0.62      0.57      0.59        14\n",
      "           4       0.56      0.50      0.53        18\n",
      "           5       0.73      0.89      0.80         9\n",
      "           6       0.58      0.69      0.63        16\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.58      0.60      0.58       107\n",
      "weighted avg       0.58      0.59      0.58       107\n",
      "\n",
      "\n",
      "Training and evaluating: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60        18\n",
      "           1       0.56      0.45      0.50        20\n",
      "           2       0.18      0.17      0.17        12\n",
      "           3       0.32      0.43      0.36        14\n",
      "           4       0.50      0.44      0.47        18\n",
      "           5       0.64      0.78      0.70         9\n",
      "           6       0.50      0.69      0.58        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.49      0.49      0.48       107\n",
      "weighted avg       0.51      0.49      0.49       107\n",
      "\n",
      "\n",
      "Training and evaluating: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.78      0.55        18\n",
      "           1       0.35      0.55      0.43        20\n",
      "           2       0.40      0.17      0.24        12\n",
      "           3       0.57      0.29      0.38        14\n",
      "           4       0.33      0.11      0.17        18\n",
      "           5       0.80      0.44      0.57         9\n",
      "           6       0.30      0.38      0.33        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.45      0.39      0.38       107\n",
      "weighted avg       0.43      0.40      0.38       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- RCC Only ---\")\n",
    "train_and_evaluate(X_rcc, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- LP Residual Only ---\n",
      "\n",
      "Training and evaluating: SVM (Linear Kernel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.61      0.39        18\n",
      "           1       0.50      0.15      0.23        20\n",
      "           2       0.14      0.08      0.11        12\n",
      "           3       0.20      0.07      0.11        14\n",
      "           4       0.75      0.17      0.27        18\n",
      "           5       0.29      0.22      0.25         9\n",
      "           6       0.30      0.75      0.43        16\n",
      "\n",
      "    accuracy                           0.31       107\n",
      "   macro avg       0.35      0.29      0.26       107\n",
      "weighted avg       0.38      0.31      0.27       107\n",
      "\n",
      "\n",
      "Training and evaluating: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.89      0.63        18\n",
      "           1       0.69      0.55      0.61        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.71      0.59        14\n",
      "           4       0.33      0.06      0.10        18\n",
      "           5       0.67      0.89      0.76         9\n",
      "           6       0.47      0.56      0.51        16\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.45      0.52      0.46       107\n",
      "weighted avg       0.46      0.51      0.45       107\n",
      "\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55        18\n",
      "           1       0.71      0.50      0.59        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.38      0.43      0.40        14\n",
      "           4       0.40      0.22      0.29        18\n",
      "           5       0.69      1.00      0.82         9\n",
      "           6       0.42      0.69      0.52        16\n",
      "\n",
      "    accuracy                           0.48       107\n",
      "   macro avg       0.44      0.49      0.45       107\n",
      "weighted avg       0.46      0.48      0.45       107\n",
      "\n",
      "\n",
      "Training and evaluating: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.72      0.50        18\n",
      "           1       0.50      0.25      0.33        20\n",
      "           2       0.20      0.08      0.12        12\n",
      "           3       0.27      0.21      0.24        14\n",
      "           4       0.50      0.17      0.25        18\n",
      "           5       0.40      0.22      0.29         9\n",
      "           6       0.31      0.69      0.42        16\n",
      "\n",
      "    accuracy                           0.36       107\n",
      "   macro avg       0.37      0.34      0.31       107\n",
      "weighted avg       0.38      0.36      0.32       107\n",
      "\n",
      "\n",
      "Training and evaluating: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.61      0.45        18\n",
      "           1       0.38      0.45      0.41        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.50      0.21      0.30        14\n",
      "           4       0.33      0.06      0.10        18\n",
      "           5       0.00      0.00      0.00         9\n",
      "           6       0.22      0.50      0.30        16\n",
      "\n",
      "    accuracy                           0.31       107\n",
      "   macro avg       0.30      0.27      0.24       107\n",
      "weighted avg       0.32      0.31      0.27       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- LP Residual Only ---\")\n",
    "train_and_evaluate(X_lp, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import scipy.signal\n",
    "from typing import Dict\n",
    "\n",
    "def extract_gvv_features(file_path: str, frame_size: float = 0.025, frame_stride: float = 0.01, n_segments: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts GVV features from an audio file using a simplified IAIF approach.\n",
    "    The features are averaged over time into an n x 1 feature matrix.\n",
    "\n",
    "    Returns:\n",
    "      np.ndarray: A (n_segments, 1) array of GVV energy values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signal, sample_rate = librosa.load(file_path, sr=None)\n",
    "        frame_length = int(frame_size * sample_rate)\n",
    "        hop_length = int(frame_stride * sample_rate)\n",
    "\n",
    "        # Pre-emphasis\n",
    "        pre_emphasis = 0.97\n",
    "        emphasized_signal = np.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "\n",
    "        # LPC Analysis\n",
    "        lpc_order = 16\n",
    "        lpc_coeffs = librosa.lpc(emphasized_signal, order=lpc_order)\n",
    "\n",
    "        # Inverse filtering (glottal excitation)\n",
    "        glottal_source = scipy.signal.lfilter(lpc_coeffs, [1.0], emphasized_signal)\n",
    "\n",
    "        # Frame the glottal source signal\n",
    "        frames = librosa.util.frame(glottal_source, frame_length=frame_length, hop_length=hop_length).T\n",
    "\n",
    "        # Energy per frame\n",
    "        frame_energies = np.sum(frames ** 2, axis=1)\n",
    "\n",
    "        # Normalize energies\n",
    "        frame_energies -= np.mean(frame_energies)\n",
    "        frame_energies /= (np.std(frame_energies) + 1e-6)\n",
    "\n",
    "        # Segment pooling\n",
    "        segments = np.array_split(frame_energies, n_segments)\n",
    "        pooled_features = np.array([np.mean(seg) for seg in segments]).reshape(-1, 1)\n",
    "\n",
    "        return pooled_features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory_gvv(directory: str, n_segments: int = 10) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts GVV features from all .wav files in the directory.\n",
    "    \"\"\"\n",
    "    feature_vectors = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            features = extract_gvv_features(file_path, n_segments=n_segments)\n",
    "            if features.size > 0:\n",
    "                feature_vectors[filename] = features.flatten()  # Flatten for classifier input\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "directory = \"./EmoDB_dataset/wav\"  # Replace with your .wav directory\n",
    "labels_csv_path = \"./EmoDB_dataset/emotion_mapping_detailed.csv\"  # Replace with your CSV\n",
    "\n",
    "# Load emotion labels\n",
    "labels_df = pd.read_csv(labels_csv_path)  # Assumes columns: 'filename', 'emotion'\n",
    "\n",
    "# Extract GVV features\n",
    "features_dict = process_directory_gvv(directory)\n",
    "\n",
    "# Align features with labels\n",
    "X, y = [], []\n",
    "\n",
    "for _, row in labels_df.iterrows():\n",
    "    fname = row['Filename']\n",
    "    if fname in features_dict:\n",
    "        X.append(features_dict[fname])\n",
    "        y.append(row['EmotionNumeric'])  # Adjust if label is in another column\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple classifiers: SVM, Random Forest, XGBoost, Logistic Regression, KNN.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM (Linear Kernel)\": SVC(kernel='linear', random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=20000, random_state=42),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=4)\n",
    "    }\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\nTraining and evaluating: {name}\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GVV ---\n",
      "\n",
      "Training and evaluating: SVM (Linear Kernel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.89      0.41        18\n",
      "           1       0.38      0.45      0.41        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.62      0.56      0.59         9\n",
      "           6       0.29      0.25      0.27        16\n",
      "\n",
      "    accuracy                           0.32       107\n",
      "   macro avg       0.22      0.31      0.24       107\n",
      "weighted avg       0.21      0.32      0.23       107\n",
      "\n",
      "\n",
      "Training and evaluating: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.89      0.53        18\n",
      "           1       0.50      0.35      0.41        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.18      0.14      0.16        14\n",
      "           4       0.33      0.17      0.22        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.33      0.38      0.35        16\n",
      "\n",
      "    accuracy                           0.38       107\n",
      "   macro avg       0.33      0.39      0.34       107\n",
      "weighted avg       0.34      0.38      0.33       107\n",
      "\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.67      0.48        18\n",
      "           1       0.50      0.40      0.44        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.32      0.43      0.36        14\n",
      "           4       0.38      0.28      0.32        18\n",
      "           5       0.56      0.56      0.56         9\n",
      "           6       0.43      0.38      0.40        16\n",
      "\n",
      "    accuracy                           0.39       107\n",
      "   macro avg       0.37      0.39      0.37       107\n",
      "weighted avg       0.37      0.39      0.37       107\n",
      "\n",
      "\n",
      "Training and evaluating: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.83      0.44        18\n",
      "           1       0.50      0.45      0.47        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.42      0.28      0.33        18\n",
      "           5       0.44      0.44      0.44         9\n",
      "           6       0.36      0.25      0.30        16\n",
      "\n",
      "    accuracy                           0.35       107\n",
      "   macro avg       0.29      0.32      0.28       107\n",
      "weighted avg       0.31      0.35      0.30       107\n",
      "\n",
      "\n",
      "Training and evaluating: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.67      0.44        18\n",
      "           1       0.40      0.40      0.40        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.30      0.21      0.25        14\n",
      "           4       0.30      0.17      0.21        18\n",
      "           5       0.44      0.44      0.44         9\n",
      "           6       0.33      0.31      0.32        16\n",
      "\n",
      "    accuracy                           0.33       107\n",
      "   macro avg       0.30      0.31      0.30       107\n",
      "weighted avg       0.31      0.33      0.30       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- GVV ---\")\n",
    "train_and_evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple classifiers: SVM, Random Forest, XGBoost, Logistic Regression, KNN.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM (Linear Kernel)\": SVC(kernel='linear', random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=25000, random_state=1331),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\nTraining and evaluating: {name}\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined dataset shape: (535, 3565)\n",
      "\n",
      "Training and evaluating: SVM (Linear Kernel)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.78      0.76        18\n",
      "           1       0.72      0.65      0.68        20\n",
      "           2       0.57      0.33      0.42        12\n",
      "           3       0.53      0.64      0.58        14\n",
      "           4       0.69      0.61      0.65        18\n",
      "           5       0.55      0.67      0.60         9\n",
      "           6       0.63      0.75      0.69        16\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.63      0.63      0.63       107\n",
      "weighted avg       0.65      0.64      0.64       107\n",
      "\n",
      "\n",
      "Training and evaluating: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59        18\n",
      "           1       0.47      0.45      0.46        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.56      0.36      0.43        14\n",
      "           4       1.00      0.11      0.20        18\n",
      "           5       0.75      1.00      0.86         9\n",
      "           6       0.41      0.56      0.47        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.52      0.50      0.43       107\n",
      "weighted avg       0.52      0.49      0.42       107\n",
      "\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.89      0.68        18\n",
      "           1       0.54      0.35      0.42        20\n",
      "           2       0.60      0.50      0.55        12\n",
      "           3       0.73      0.57      0.64        14\n",
      "           4       0.67      0.33      0.44        18\n",
      "           5       0.75      1.00      0.86         9\n",
      "           6       0.48      0.69      0.56        16\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.62      0.62      0.59       107\n",
      "weighted avg       0.60      0.59      0.57       107\n",
      "\n",
      "\n",
      "Training and evaluating: Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.67        18\n",
      "           1       0.73      0.55      0.63        20\n",
      "           2       0.60      0.25      0.35        12\n",
      "           3       0.56      0.64      0.60        14\n",
      "           4       0.56      0.50      0.53        18\n",
      "           5       0.62      0.89      0.73         9\n",
      "           6       0.62      0.81      0.70        16\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.62      0.60       107\n",
      "weighted avg       0.62      0.62      0.60       107\n",
      "\n",
      "\n",
      "Training and evaluating: K-Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.78      0.57        18\n",
      "           1       0.32      0.50      0.39        20\n",
      "           2       0.40      0.17      0.24        12\n",
      "           3       0.50      0.29      0.36        14\n",
      "           4       0.50      0.11      0.18        18\n",
      "           5       0.80      0.44      0.57         9\n",
      "           6       0.30      0.44      0.36        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.47      0.39      0.38       107\n",
      "weighted avg       0.44      0.40      0.38       107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load features from each method.\n",
    "mfcc_features = process_directory_mfcc(directory, n_segments=85)\n",
    "rcc_lp_features = process_directory_rcc_lp(directory, target_rcc_segments=10, target_lp_segments=120, rcc_order=12)\n",
    "gvv_features = process_directory_gvv(directory, n_segments=10)\n",
    "\n",
    "# Combine features by appending (concatenation)\n",
    "combined_features = {}\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.wav'):\n",
    "        # Check that all features exist for this file\n",
    "        if filename in mfcc_features and filename in rcc_lp_features and filename in gvv_features:\n",
    "            mfcc_vec = mfcc_features[filename].flatten()         # e.g., shape (85*39,)\n",
    "            rcc_lp_vec = rcc_lp_features[filename][\"Full\"]         # already flattened concatenation of RCC and LP\n",
    "            gvv_vec = gvv_features[filename].flatten()             # e.g., shape (10,)\n",
    "            combined = np.concatenate([mfcc_vec, rcc_lp_vec, gvv_vec])\n",
    "            combined_features[filename] = combined\n",
    "\n",
    "# Prepare dataset using the combined feature vectors.\n",
    "def prepare_combined_dataset(features: dict, labels: pd.DataFrame):\n",
    "    X, y = [], []\n",
    "    for _, row in labels.iterrows():\n",
    "        file_id = row['Filename']\n",
    "        if file_id in features:\n",
    "            X.append(features[file_id])\n",
    "            y.append(int(row['EmotionNumeric']))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "labels = pd.read_csv(\"EmoDB_dataset/emotion_mapping_detailed.csv\")\n",
    "X_combined, y_combined = prepare_combined_dataset(combined_features, labels)\n",
    "print(\"Combined dataset shape:\", X_combined.shape)\n",
    "\n",
    "# Train and evaluate classifier on the combined feature set\n",
    "train_and_evaluate(X_combined, y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
