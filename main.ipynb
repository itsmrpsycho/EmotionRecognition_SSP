{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './EmoDB_dataset/wav'\n",
    "labels_csv_path = \"./EmoDB_dataset/emotion_mapping_detailed.csv\"  # Replace with your CSV path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def train_and_evaluate(X, y):\n",
    "    \"\"\"\n",
    "    Train and evaluate multiple classifiers and return metrics dictionary.\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.ndarray): Feature matrix\n",
    "        y (np.ndarray): Target labels\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing metrics for each classifier\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    classifiers = {\n",
    "        \"SVM\": SVC(kernel='linear', random_state=42),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='mlogloss', random_state=42),\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=20000, random_state=42),\n",
    "        \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        print(f\"\\nTraining and evaluating: {name}\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "        \n",
    "        # Store metrics in dictionary\n",
    "        metrics[f\"{name}_Accuracy\"] = accuracy\n",
    "        metrics[f\"{name}_Precision\"] = precision\n",
    "        metrics[f\"{name}_Recall\"] = recall\n",
    "        metrics[f\"{name}_F1\"] = f1\n",
    "        \n",
    "        # Print classification report for reference\n",
    "        print(classification_report(y_test, y_pred, zero_division=0))\n",
    "        print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "def extract_mfcc_features(file_path: str, n_mfcc: int = 39, \n",
    "                          frame_size: float = 0.025, frame_stride: float = 0.01, \n",
    "                          n_segments: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts 39 MFCC features framewise from an audio file and then applies\n",
    "    average pooling to condense the features over time into an n x 39 feature matrix.\n",
    "    \n",
    "    Parameters:\n",
    "      file_path (str): Path to the audio file.\n",
    "      n_mfcc (int): Number of MFCC features to extract. Default is 39.\n",
    "      frame_size (float): Length of each frame in seconds. Default is 0.025.\n",
    "      frame_stride (float): Step between successive frames in seconds. Default is 0.01.\n",
    "      n_segments (int): Number of segments (n) to pool the frames into.\n",
    "    \n",
    "    Returns:\n",
    "      np.ndarray: A n x 39 array where each row is the average MFCC vector for that segment.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signal, sample_rate = librosa.load(file_path, sr=None)\n",
    "        frame_length = int(frame_size * sample_rate)\n",
    "        hop_length = int(frame_stride * sample_rate)\n",
    "        \n",
    "        # Extract MFCC features; result shape is (n_mfcc, T) where T is number of frames.\n",
    "        mfcc = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=n_mfcc,\n",
    "                                    n_fft=frame_length, hop_length=hop_length)\n",
    "        \n",
    "        # Normalize the MFCC features along each coefficient dimension.\n",
    "        mfcc_normalized = mfcc - np.mean(mfcc, axis=1, keepdims=True)\n",
    "        \n",
    "        # Transpose to shape (T, n_mfcc) for pooling along the time axis.\n",
    "        mfcc_normalized = mfcc_normalized.T\n",
    "        \n",
    "        # Divide the frames into n_segments segments and compute the average for each segment.\n",
    "        segments = np.array_split(mfcc_normalized, n_segments, axis=0)\n",
    "        pooled_features = np.array([np.mean(seg, axis=0) for seg in segments])\n",
    "        \n",
    "        return pooled_features  # Shape: (n_segments, 39)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "    return np.array([])\n",
    "\n",
    "def process_directory_mfcc(directory: str, n_segments: int = 10) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Processes all .wav files in the given directory, extracting their MFCC features\n",
    "    using average pooling to produce an n x 39 feature matrix for each file.\n",
    "    \n",
    "    Parameters:\n",
    "      directory (str): Path to the directory containing .wav files.\n",
    "      n_segments (int): Number of segments to pool the frames into for each file.\n",
    "    \n",
    "    Returns:\n",
    "      Dict[str, np.ndarray]: A dictionary mapping filenames to their corresponding feature matrices.\n",
    "    \"\"\"\n",
    "    feature_vectors = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            features = extract_mfcc_features(file_path, n_segments=n_segments)\n",
    "            if features.size > 0:\n",
    "                feature_vectors[filename] = features\n",
    "    return feature_vectors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier on MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "\n",
    "def load_labels(csv_file: str) -> pd.DataFrame:\n",
    "    return pd.read_csv(csv_file)\n",
    "\n",
    "def prepare_dataset_mfcc(features: dict, labels: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Constructs the dataset by matching each audio file's feature matrix with its label.\n",
    "    Since each file is represented as an n x 39 matrix (n segments by 39 features),\n",
    "    we flatten it into a 1D feature vector of length n*39.\n",
    "    \"\"\"\n",
    "    X = []\n",
    "    y = []\n",
    "    for _, row in labels.iterrows():\n",
    "        file_id = row['Filename']\n",
    "        if file_id in features:\n",
    "            # Flatten the (n, 39) matrix to a 1D vector (n*39,)\n",
    "            feature_matrix = features[file_id]\n",
    "            feature_vector = feature_matrix.flatten()\n",
    "            X.append(feature_vector)\n",
    "            y.append(int(row['EmotionNumeric']))\n",
    "    return np.array(X), np.array(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>▁</td></tr><tr><td>KNN_F1</td><td>▁</td></tr><tr><td>KNN_Precision</td><td>▁</td></tr><tr><td>KNN_Recall</td><td>▁</td></tr><tr><td>LogisticRegression_Accuracy</td><td>▁</td></tr><tr><td>LogisticRegression_F1</td><td>▁</td></tr><tr><td>LogisticRegression_Precision</td><td>▁</td></tr><tr><td>LogisticRegression_Recall</td><td>▁</td></tr><tr><td>RandomForest_Accuracy</td><td>▁</td></tr><tr><td>RandomForest_F1</td><td>▁</td></tr><tr><td>RandomForest_Precision</td><td>▁</td></tr><tr><td>RandomForest_Recall</td><td>▁</td></tr><tr><td>SVM_Accuracy</td><td>▁</td></tr><tr><td>SVM_F1</td><td>▁</td></tr><tr><td>SVM_Precision</td><td>▁</td></tr><tr><td>SVM_Recall</td><td>▁</td></tr><tr><td>XGBoost_Accuracy</td><td>▁</td></tr><tr><td>XGBoost_F1</td><td>▁</td></tr><tr><td>XGBoost_Precision</td><td>▁</td></tr><tr><td>XGBoost_Recall</td><td>▁</td></tr><tr><td>feature_dim</td><td>▁</td></tr><tr><td>n_segments</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>0.43925</td></tr><tr><td>KNN_F1</td><td>0.41414</td></tr><tr><td>KNN_Precision</td><td>0.43893</td></tr><tr><td>KNN_Recall</td><td>0.43925</td></tr><tr><td>LogisticRegression_Accuracy</td><td>0.53271</td></tr><tr><td>LogisticRegression_F1</td><td>0.53488</td></tr><tr><td>LogisticRegression_Precision</td><td>0.5485</td></tr><tr><td>LogisticRegression_Recall</td><td>0.53271</td></tr><tr><td>MFCC_n5_best_accuracy</td><td>0.53271</td></tr><tr><td>RandomForest_Accuracy</td><td>0.43925</td></tr><tr><td>RandomForest_F1</td><td>0.38136</td></tr><tr><td>RandomForest_Precision</td><td>0.49855</td></tr><tr><td>RandomForest_Recall</td><td>0.43925</td></tr><tr><td>SVM_Accuracy</td><td>0.52336</td></tr><tr><td>SVM_F1</td><td>0.50534</td></tr><tr><td>SVM_Precision</td><td>0.51939</td></tr><tr><td>SVM_Recall</td><td>0.52336</td></tr><tr><td>XGBoost_Accuracy</td><td>0.49533</td></tr><tr><td>XGBoost_F1</td><td>0.46913</td></tr><tr><td>XGBoost_Precision</td><td>0.48741</td></tr><tr><td>XGBoost_Recall</td><td>0.49533</td></tr><tr><td>feature_dim</td><td>195</td></tr><tr><td>feature_type</td><td>MFCC</td></tr><tr><td>n_segments</td><td>5</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-mfcc-classification</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/h3jea49i' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/h3jea49i</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_230221-h3jea49i\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\College\\4-2\\SSP\\SSP_Project\\newProject\\EmotionRecognition_SSP\\wandb\\run-20250421_230232-ymrtbwro</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/ymrtbwro' target=\"_blank\">ssp-mfcc-classification</a></strong> to <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/ymrtbwro' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/ymrtbwro</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for n_segments = 5\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 195)\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.83      0.59        18\n",
      "           1       0.71      0.75      0.73        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.62      0.36      0.45        14\n",
      "           4       0.71      0.56      0.62        18\n",
      "           5       0.50      0.44      0.47         9\n",
      "           6       0.44      0.44      0.44        16\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.49      0.48      0.47       107\n",
      "weighted avg       0.52      0.52      0.51       107\n",
      "\n",
      "Accuracy: 0.5234, Precision: 0.5194, Recall: 0.5234, F1: 0.5053\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.78      0.42        18\n",
      "           1       0.61      0.70      0.65        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.25      0.07      0.11        14\n",
      "           4       1.00      0.11      0.20        18\n",
      "           5       0.88      0.78      0.82         9\n",
      "           6       0.41      0.56      0.47        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.49      0.43      0.38       107\n",
      "weighted avg       0.50      0.44      0.38       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4985, Recall: 0.4393, F1: 0.3814\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.72      0.57        18\n",
      "           1       0.69      0.55      0.61        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.43      0.46        14\n",
      "           4       0.67      0.33      0.44        18\n",
      "           5       0.50      0.89      0.64         9\n",
      "           6       0.41      0.56      0.47        16\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.46      0.50      0.46       107\n",
      "weighted avg       0.49      0.50      0.47       107\n",
      "\n",
      "Accuracy: 0.4953, Precision: 0.4874, Recall: 0.4953, F1: 0.4691\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.61      0.49        18\n",
      "           1       0.74      0.70      0.72        20\n",
      "           2       0.33      0.33      0.33        12\n",
      "           3       0.67      0.57      0.62        14\n",
      "           4       0.64      0.50      0.56        18\n",
      "           5       0.67      0.67      0.67         9\n",
      "           6       0.36      0.31      0.33        16\n",
      "\n",
      "    accuracy                           0.53       107\n",
      "   macro avg       0.54      0.53      0.53       107\n",
      "weighted avg       0.55      0.53      0.53       107\n",
      "\n",
      "Accuracy: 0.5327, Precision: 0.5485, Recall: 0.5327, F1: 0.5349\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.72      0.48        18\n",
      "           1       0.73      0.55      0.63        20\n",
      "           2       0.29      0.17      0.21        12\n",
      "           3       0.33      0.21      0.26        14\n",
      "           4       0.29      0.11      0.16        18\n",
      "           5       0.70      0.78      0.74         9\n",
      "           6       0.39      0.56      0.46        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.44      0.44      0.42       107\n",
      "weighted avg       0.44      0.44      0.41       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4389, Recall: 0.4393, F1: 0.4141\n",
      "\n",
      "Running for n_segments = 10\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 390)\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.67      0.56        18\n",
      "           1       0.75      0.60      0.67        20\n",
      "           2       0.50      0.25      0.33        12\n",
      "           3       0.38      0.43      0.40        14\n",
      "           4       0.69      0.61      0.65        18\n",
      "           5       0.62      0.89      0.73         9\n",
      "           6       0.53      0.50      0.52        16\n",
      "\n",
      "    accuracy                           0.56       107\n",
      "   macro avg       0.56      0.56      0.55       107\n",
      "weighted avg       0.57      0.56      0.56       107\n",
      "\n",
      "Accuracy: 0.5607, Precision: 0.5732, Recall: 0.5607, F1: 0.5554\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.94      0.51        18\n",
      "           1       0.75      0.60      0.67        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.67      0.11      0.19        18\n",
      "           5       0.67      0.89      0.76         9\n",
      "           6       0.52      0.75      0.62        16\n",
      "\n",
      "    accuracy                           0.48       107\n",
      "   macro avg       0.42      0.47      0.39       107\n",
      "weighted avg       0.44      0.48      0.40       107\n",
      "\n",
      "Accuracy: 0.4766, Precision: 0.4448, Recall: 0.4766, F1: 0.3981\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.67      0.47        18\n",
      "           1       0.80      0.60      0.69        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.33      0.29      0.31        14\n",
      "           4       0.44      0.39      0.41        18\n",
      "           5       0.75      1.00      0.86         9\n",
      "           6       0.47      0.50      0.48        16\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.52      0.50      0.48       107\n",
      "weighted avg       0.52      0.50      0.48       107\n",
      "\n",
      "Accuracy: 0.4953, Precision: 0.5174, Recall: 0.4953, F1: 0.4775\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.56      0.53        18\n",
      "           1       0.67      0.40      0.50        20\n",
      "           2       0.62      0.42      0.50        12\n",
      "           3       0.50      0.43      0.46        14\n",
      "           4       0.55      0.61      0.58        18\n",
      "           5       0.50      0.89      0.64         9\n",
      "           6       0.42      0.50      0.46        16\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.54      0.54      0.52       107\n",
      "weighted avg       0.54      0.52      0.52       107\n",
      "\n",
      "Accuracy: 0.5234, Precision: 0.5418, Recall: 0.5234, F1: 0.5180\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.78      0.60        18\n",
      "           1       0.29      0.30      0.29        20\n",
      "           2       0.40      0.17      0.24        12\n",
      "           3       0.44      0.29      0.35        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.78      0.78      0.78         9\n",
      "           6       0.29      0.56      0.38        16\n",
      "\n",
      "    accuracy                           0.39       107\n",
      "   macro avg       0.38      0.41      0.38       107\n",
      "weighted avg       0.35      0.39      0.35       107\n",
      "\n",
      "Accuracy: 0.3925, Precision: 0.3465, Recall: 0.3925, F1: 0.3495\n",
      "\n",
      "Running for n_segments = 15\n",
      "Number of files processed: 535\n",
      "Dataset shape: (535, 585)\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.72      0.57        18\n",
      "           1       0.75      0.60      0.67        20\n",
      "           2       0.67      0.17      0.27        12\n",
      "           3       0.36      0.36      0.36        14\n",
      "           4       0.53      0.50      0.51        18\n",
      "           5       0.46      0.67      0.55         9\n",
      "           6       0.50      0.50      0.50        16\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.50      0.49       107\n",
      "weighted avg       0.54      0.51      0.50       107\n",
      "\n",
      "Accuracy: 0.5140, Precision: 0.5424, Recall: 0.5140, F1: 0.5035\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.83      0.47        18\n",
      "           1       0.74      0.70      0.72        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       1.00      0.17      0.29        18\n",
      "           5       0.80      0.89      0.84         9\n",
      "           6       0.35      0.56      0.43        16\n",
      "\n",
      "    accuracy                           0.46       107\n",
      "   macro avg       0.46      0.45      0.39       107\n",
      "weighted avg       0.48      0.46      0.40       107\n",
      "\n",
      "Accuracy: 0.4579, Precision: 0.4799, Recall: 0.4579, F1: 0.3960\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59        18\n",
      "           1       0.64      0.35      0.45        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.31      0.36      0.33        14\n",
      "           4       0.67      0.44      0.53        18\n",
      "           5       0.70      0.78      0.74         9\n",
      "           6       0.29      0.50      0.36        16\n",
      "\n",
      "    accuracy                           0.46       107\n",
      "   macro avg       0.48      0.46      0.45       107\n",
      "weighted avg       0.49      0.46      0.45       107\n",
      "\n",
      "Accuracy: 0.4579, Precision: 0.4857, Recall: 0.4579, F1: 0.4475\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.61      0.48        18\n",
      "           1       0.75      0.45      0.56        20\n",
      "           2       0.50      0.33      0.40        12\n",
      "           3       0.33      0.29      0.31        14\n",
      "           4       0.47      0.39      0.42        18\n",
      "           5       0.31      0.56      0.40         9\n",
      "           6       0.50      0.50      0.50        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.47      0.45      0.44       107\n",
      "weighted avg       0.49      0.45      0.45       107\n",
      "\n",
      "Accuracy: 0.4486, Precision: 0.4855, Recall: 0.4486, F1: 0.4505\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59        18\n",
      "           1       0.41      0.35      0.38        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.38      0.36      0.37        14\n",
      "           4       0.60      0.17      0.26        18\n",
      "           5       0.50      0.67      0.57         9\n",
      "           6       0.35      0.69      0.47        16\n",
      "\n",
      "    accuracy                           0.43       107\n",
      "   macro avg       0.44      0.43      0.40       107\n",
      "weighted avg       0.44      0.43      0.40       107\n",
      "\n",
      "Accuracy: 0.4299, Precision: 0.4448, Recall: 0.4299, F1: 0.3955\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>█▁▇</td></tr><tr><td>KNN_F1</td><td>█▁▆</td></tr><tr><td>KNN_Precision</td><td>█▁█</td></tr><tr><td>KNN_Recall</td><td>█▁▇</td></tr><tr><td>LogisticRegression_Accuracy</td><td>█▇▁</td></tr><tr><td>LogisticRegression_F1</td><td>█▇▁</td></tr><tr><td>LogisticRegression_Precision</td><td>█▇▁</td></tr><tr><td>LogisticRegression_Recall</td><td>█▇▁</td></tr><tr><td>RandomForest_Accuracy</td><td>▁█▄</td></tr><tr><td>RandomForest_F1</td><td>▁█▇</td></tr><tr><td>RandomForest_Precision</td><td>█▁▆</td></tr><tr><td>RandomForest_Recall</td><td>▁█▄</td></tr><tr><td>SVM_Accuracy</td><td>▂█▁</td></tr><tr><td>SVM_F1</td><td>▁█▁</td></tr><tr><td>SVM_Precision</td><td>▁█▄</td></tr><tr><td>SVM_Recall</td><td>▂█▁</td></tr><tr><td>XGBoost_Accuracy</td><td>██▁</td></tr><tr><td>XGBoost_F1</td><td>▆█▁</td></tr><tr><td>XGBoost_Precision</td><td>▁█▁</td></tr><tr><td>XGBoost_Recall</td><td>██▁</td></tr><tr><td>feature_dim</td><td>▁▄█</td></tr><tr><td>n_segments</td><td>▁▅█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>0.42991</td></tr><tr><td>KNN_F1</td><td>0.39549</td></tr><tr><td>KNN_Precision</td><td>0.44483</td></tr><tr><td>KNN_Recall</td><td>0.42991</td></tr><tr><td>LogisticRegression_Accuracy</td><td>0.4486</td></tr><tr><td>LogisticRegression_F1</td><td>0.45049</td></tr><tr><td>LogisticRegression_Precision</td><td>0.48552</td></tr><tr><td>LogisticRegression_Recall</td><td>0.4486</td></tr><tr><td>MFCC_n10_best_accuracy</td><td>0.56075</td></tr><tr><td>MFCC_n15_best_accuracy</td><td>0.51402</td></tr><tr><td>MFCC_n5_best_accuracy</td><td>0.53271</td></tr><tr><td>RandomForest_Accuracy</td><td>0.45794</td></tr><tr><td>RandomForest_F1</td><td>0.39603</td></tr><tr><td>RandomForest_Precision</td><td>0.47986</td></tr><tr><td>RandomForest_Recall</td><td>0.45794</td></tr><tr><td>SVM_Accuracy</td><td>0.51402</td></tr><tr><td>SVM_F1</td><td>0.50349</td></tr><tr><td>SVM_Precision</td><td>0.54243</td></tr><tr><td>SVM_Recall</td><td>0.51402</td></tr><tr><td>XGBoost_Accuracy</td><td>0.45794</td></tr><tr><td>XGBoost_F1</td><td>0.44752</td></tr><tr><td>XGBoost_Precision</td><td>0.48574</td></tr><tr><td>XGBoost_Recall</td><td>0.45794</td></tr><tr><td>feature_dim</td><td>585</td></tr><tr><td>feature_type</td><td>MFCC</td></tr><tr><td>n_segments</td><td>15</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-mfcc-classification</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/ymrtbwro' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/ymrtbwro</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_230232-ymrtbwro\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"emotion-recognition\", name=\"ssp-mfcc-classification\")\n",
    "\n",
    "# Example usage: Varying n\n",
    "n_values = np.arange(5, 110, 5)  # n_segments from 5 to 100 in steps of 5\n",
    "labels = load_labels(labels_csv_path)\n",
    "\n",
    "for n in n_values:\n",
    "    print(f\"\\nRunning for n_segments = {n}\")\n",
    "    \n",
    "    # Extract MFCC features with the current n\n",
    "    mfccFeatures = process_directory_mfcc(directory, n)\n",
    "    print(f\"Number of files processed: {len(mfccFeatures)}\")\n",
    "    \n",
    "    # Prepare the dataset: each feature matrix is flattened to become a vector\n",
    "    X, y = prepare_dataset_mfcc(mfccFeatures, labels)\n",
    "    print(\"Dataset shape:\", X.shape)\n",
    "    \n",
    "    # Train and evaluate classifiers, logging metrics to wandb\n",
    "    metrics = train_and_evaluate(X, y)\n",
    "    \n",
    "    # Log metrics to wandb with the 'n' value\n",
    "    log_data = {\n",
    "        \"n_segments\": n,\n",
    "        \"feature_type\": \"MFCC\",\n",
    "        \"feature_dim\": X.shape[1],\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    wandb.log(log_data)\n",
    "    \n",
    "    # Optional: You could also create a summary table for easy comparison\n",
    "    wandb.run.summary[f\"MFCC_n{n}_best_accuracy\"] = max([\n",
    "        metrics.get(\"SVM_Accuracy\", 0),\n",
    "        metrics.get(\"RandomForest_Accuracy\", 0),\n",
    "        metrics.get(\"XGBoost_Accuracy\", 0),\n",
    "        metrics.get(\"LogisticRegression_Accuracy\", 0),\n",
    "        metrics.get(\"KNN_Accuracy\", 0)\n",
    "    ])\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import lfilter\n",
    "from scipy.fftpack import dct\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.fftpack import dct\n",
    "from scipy.signal import lfilter\n",
    "\n",
    "def extract_rcc(frame: np.ndarray, order: int = 12, n_rcc: int = 12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extract Residual Cepstral Coefficients (RCC) from a signal frame using LPC and residual signal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: LPC Analysis - Calculate the LPC coefficients (Prediction Coefficients)\n",
    "        autocorr = np.correlate(frame, frame, mode='full')\n",
    "        autocorr = autocorr[len(autocorr)//2:]  # Keep second half (autocorrelation)\n",
    "        \n",
    "        if autocorr[0] == 0:\n",
    "            return np.zeros(n_rcc)  # Silent frame, return zero vector\n",
    "        \n",
    "        # Levinson-Durbin recursion to solve for LPC coefficients\n",
    "        a = np.zeros(order + 1)\n",
    "        e = autocorr[0]\n",
    "        k = np.zeros(order)\n",
    "\n",
    "        for i in range(order):\n",
    "            acc = autocorr[i + 1] - np.dot(a[1:i + 1], autocorr[i:0:-1])\n",
    "            ki = acc / e\n",
    "            k[i] = ki\n",
    "            a[1:i+1] -= ki * a[i:0:-1]\n",
    "            a[i + 1] = ki\n",
    "            e *= (1 - ki ** 2)\n",
    "\n",
    "        # Step 2: Compute the residual signal by filtering the frame using LPC coefficients\n",
    "        residual = lfilter(a, [1.0], frame)\n",
    "        \n",
    "        # Step 3: Apply Cepstral Analysis (DCT) to the residual signal\n",
    "        # We use the first n_rcc coefficients from the DCT of the log of the residual power spectrum\n",
    "        residual_power_spectrum = np.abs(np.fft.fft(residual)) ** 2\n",
    "        log_residual_spectrum = np.log(residual_power_spectrum + 1e-8)  # Log power spectrum\n",
    "\n",
    "        # Compute the DCT (Discrete Cosine Transform)\n",
    "        rcc = dct(log_residual_spectrum, type=2)[:n_rcc]\n",
    "        \n",
    "        return rcc\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting RCC: {e}\")\n",
    "        return np.zeros(n_rcc)  # Return zero vector in case of error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import lfilter\n",
    "from scipy.fftpack import dct\n",
    "\n",
    "def extract_rcc_features(file_path: str,\n",
    "                         frame_size: float = 0.025,\n",
    "                         frame_stride: float = 0.01,\n",
    "                         target_rcc_segments: int = 100,\n",
    "                         rcc_order: int = 12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts Residual Cepstral Coefficients (RCC) features framewise then condenses \n",
    "    the features into a fixed-length feature matrix via average pooling.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        frame_size (float): Frame duration in seconds.\n",
    "        frame_stride (float): Step between successive frames in seconds.\n",
    "        target_rcc_segments (int): Desired number of pooled segments for RCC features.\n",
    "        rcc_order (int): Number of RCC coefficients to extract per frame.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Pooled RCC features with shape (target_rcc_segments, rcc_order).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signal, sr = librosa.load(file_path, sr=None)\n",
    "        frame_length = int(frame_size * sr)\n",
    "        hop_length = int(frame_stride * sr)\n",
    "        \n",
    "        # Frame the signal: shape (number_of_frames, frame_length)\n",
    "        frames = librosa.util.frame(signal, frame_length=frame_length, hop_length=hop_length).T\n",
    "\n",
    "        rcc_list = []\n",
    "        \n",
    "        for frame in frames:\n",
    "            # Apply windowing\n",
    "            frame = frame * np.hamming(len(frame))\n",
    "            \n",
    "            # RCC extraction: use LPC analysis then DCT of the log power spectrum\n",
    "            try:\n",
    "                # Compute autocorrelation for LPC\n",
    "                autocorr = np.correlate(frame, frame, mode='full')\n",
    "                autocorr = autocorr[len(autocorr)//2:]\n",
    "                if autocorr[0] == 0:\n",
    "                    rcc = np.zeros(rcc_order)\n",
    "                else:\n",
    "                    a = np.zeros(rcc_order + 1)\n",
    "                    e = autocorr[0]\n",
    "                    for i in range(rcc_order):\n",
    "                        acc = autocorr[i + 1] - np.dot(a[1:i+1], autocorr[i:0:-1])\n",
    "                        ki = acc / e\n",
    "                        a[1:i+1] -= ki * a[i:0:-1]\n",
    "                        a[i + 1] = ki\n",
    "                        e *= (1 - ki ** 2)\n",
    "                    # Residual signal\n",
    "                    residual = lfilter(a, [1.0], frame)\n",
    "                    # Compute RCC using DCT\n",
    "                    residual_power_spectrum = np.abs(np.fft.fft(residual)) ** 2\n",
    "                    log_residual_spectrum = np.log(residual_power_spectrum + 1e-8)\n",
    "                    rcc = dct(log_residual_spectrum, type=2)[:rcc_order]\n",
    "            except Exception as ex:\n",
    "                print(f\"Error in RCC extraction for frame: {ex}\")\n",
    "                rcc = np.zeros(rcc_order)\n",
    "            \n",
    "            rcc_list.append(rcc)\n",
    "\n",
    "        rcc_array = np.array(rcc_list)  # shape: (num_frames, rcc_order)\n",
    "        \n",
    "        # Average pool features to desired length\n",
    "        rcc_segments = np.array_split(rcc_array, target_rcc_segments, axis=0)\n",
    "        rcc_pooled = np.array([np.mean(seg, axis=0) for seg in rcc_segments])\n",
    "        \n",
    "        return rcc_pooled\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path} for RCC: {e}\")\n",
    "        return np.zeros((target_rcc_segments, rcc_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "def process_directory_rcc(directory: str,\n",
    "                          frame_size: float = 0.025,\n",
    "                          frame_stride: float = 0.01,\n",
    "                          target_rcc_segments: int = 100,\n",
    "                          rcc_order: int = 12) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Processes all .wav files in the directory and extracts RCC features.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing .wav files.\n",
    "        frame_size (float): Frame duration in seconds.\n",
    "        frame_stride (float): Step between successive frames in seconds.\n",
    "        target_rcc_segments (int): Desired number of pooled segments for RCC features.\n",
    "        rcc_order (int): Number of RCC coefficients to extract per frame.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of filename to flattened RCC feature vectors.\n",
    "    \"\"\"\n",
    "    feature_vectors = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                rcc_features = extract_rcc_features(\n",
    "                    file_path,\n",
    "                    frame_size=frame_size,\n",
    "                    frame_stride=frame_stride,\n",
    "                    target_rcc_segments=target_rcc_segments,\n",
    "                    rcc_order=rcc_order\n",
    "                )\n",
    "                rcc_flat = rcc_features.flatten()  # Shape: (target_rcc_segments * rcc_order,)\n",
    "                feature_vectors[filename] = rcc_flat\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing RCC for {file_path}: {e}\")\n",
    "\n",
    "    return feature_vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_rcc_dataset(features: dict, labels: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prepares RCC feature set for classification.\n",
    "\n",
    "    Parameters:\n",
    "        features (dict): Dictionary mapping filenames to RCC feature vectors.\n",
    "        labels (pd.DataFrame): DataFrame containing emotion labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            np.ndarray: RCC features.\n",
    "            np.ndarray: Emotion labels.\n",
    "    \"\"\"\n",
    "    X_rcc, y = [], []\n",
    "\n",
    "    for _, row in labels.iterrows():\n",
    "        file_id = row['Filename']\n",
    "        if file_id in features:\n",
    "            # Direct access to feature vector (no nested dictionary)\n",
    "            X_rcc.append(features[file_id])\n",
    "            y.append(int(row['EmotionNumeric']))\n",
    "\n",
    "    return np.array(X_rcc), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\College\\4-2\\SSP\\SSP_Project\\newProject\\EmotionRecognition_SSP\\wandb\\run-20250421_230648-26ilsodu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/26ilsodu' target=\"_blank\">ssp-rcc-classification</a></strong> to <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/26ilsodu' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/26ilsodu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for target_rcc_segments = 5\n",
      "Number of files processed: 535\n",
      "RCC-only shape: (535, 60)\n",
      "\n",
      "--- RCC with 5 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61        18\n",
      "           1       0.56      0.50      0.53        20\n",
      "           2       0.23      0.25      0.24        12\n",
      "           3       0.47      0.50      0.48        14\n",
      "           4       0.62      0.56      0.59        18\n",
      "           5       0.75      0.67      0.71         9\n",
      "           6       0.37      0.44      0.40        16\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.52      0.50      0.51       107\n",
      "weighted avg       0.52      0.50      0.51       107\n",
      "\n",
      "Accuracy: 0.5047, Precision: 0.5169, Recall: 0.5047, F1: 0.5094\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.83      0.64        18\n",
      "           1       0.48      0.50      0.49        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.64      0.64      0.64        14\n",
      "           4       0.85      0.61      0.71        18\n",
      "           5       0.90      1.00      0.95         9\n",
      "           6       0.39      0.44      0.41        16\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.61      0.59      0.57       107\n",
      "weighted avg       0.59      0.58      0.56       107\n",
      "\n",
      "Accuracy: 0.5794, Precision: 0.5924, Recall: 0.5794, F1: 0.5593\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.83      0.67        18\n",
      "           1       0.53      0.45      0.49        20\n",
      "           2       0.33      0.17      0.22        12\n",
      "           3       0.50      0.64      0.56        14\n",
      "           4       0.67      0.44      0.53        18\n",
      "           5       0.90      1.00      0.95         9\n",
      "           6       0.41      0.44      0.42        16\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.56      0.57      0.55       107\n",
      "weighted avg       0.54      0.55      0.53       107\n",
      "\n",
      "Accuracy: 0.5514, Precision: 0.5446, Recall: 0.5514, F1: 0.5344\n",
      "\n",
      "Training and evaluating: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.72      0.70        18\n",
      "           1       0.50      0.45      0.47        20\n",
      "           2       0.25      0.17      0.20        12\n",
      "           3       0.50      0.57      0.53        14\n",
      "           4       0.63      0.67      0.65        18\n",
      "           5       0.80      0.89      0.84         9\n",
      "           6       0.41      0.44      0.42        16\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.54      0.56      0.55       107\n",
      "weighted avg       0.54      0.55      0.54       107\n",
      "\n",
      "Accuracy: 0.5514, Precision: 0.5371, Recall: 0.5514, F1: 0.5424\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.83      0.53        18\n",
      "           1       0.48      0.70      0.57        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.40      0.29      0.33        14\n",
      "           4       0.29      0.11      0.16        18\n",
      "           5       0.67      0.67      0.67         9\n",
      "           6       0.22      0.12      0.16        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.35      0.39      0.35       107\n",
      "weighted avg       0.34      0.40      0.35       107\n",
      "\n",
      "Accuracy: 0.4019, Precision: 0.3446, Recall: 0.4019, F1: 0.3459\n",
      "\n",
      "Running for target_rcc_segments = 10\n",
      "Number of files processed: 535\n",
      "RCC-only shape: (535, 120)\n",
      "\n",
      "--- RCC with 10 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.67      0.65        18\n",
      "           1       0.67      0.50      0.57        20\n",
      "           2       0.43      0.25      0.32        12\n",
      "           3       0.47      0.64      0.55        14\n",
      "           4       0.59      0.56      0.57        18\n",
      "           5       0.56      0.56      0.56         9\n",
      "           6       0.57      0.75      0.65        16\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.56      0.56      0.55       107\n",
      "weighted avg       0.57      0.57      0.56       107\n",
      "\n",
      "Accuracy: 0.5701, Precision: 0.5720, Recall: 0.5701, F1: 0.5626\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.89      0.64        18\n",
      "           1       0.59      0.65      0.62        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.45      0.36      0.40        14\n",
      "           4       0.75      0.50      0.60        18\n",
      "           5       0.75      1.00      0.86         9\n",
      "           6       0.38      0.38      0.38        16\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.56      0.55      0.52       107\n",
      "weighted avg       0.56      0.55      0.52       107\n",
      "\n",
      "Accuracy: 0.5514, Precision: 0.5554, Recall: 0.5514, F1: 0.5208\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.67        18\n",
      "           1       0.67      0.50      0.57        20\n",
      "           2       0.33      0.25      0.29        12\n",
      "           3       0.62      0.57      0.59        14\n",
      "           4       0.56      0.50      0.53        18\n",
      "           5       0.73      0.89      0.80         9\n",
      "           6       0.58      0.69      0.63        16\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.58      0.60      0.58       107\n",
      "weighted avg       0.58      0.59      0.58       107\n",
      "\n",
      "Accuracy: 0.5888, Precision: 0.5830, Recall: 0.5888, F1: 0.5789\n",
      "\n",
      "Training and evaluating: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF F,G EVALUATIONS EXCEEDS LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60        18\n",
      "           1       0.56      0.45      0.50        20\n",
      "           2       0.18      0.17      0.17        12\n",
      "           3       0.32      0.43      0.36        14\n",
      "           4       0.50      0.44      0.47        18\n",
      "           5       0.64      0.78      0.70         9\n",
      "           6       0.50      0.69      0.58        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.49      0.49      0.48       107\n",
      "weighted avg       0.51      0.49      0.49       107\n",
      "\n",
      "Accuracy: 0.4860, Precision: 0.5054, Recall: 0.4860, F1: 0.4861\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.78      0.55        18\n",
      "           1       0.35      0.55      0.43        20\n",
      "           2       0.40      0.17      0.24        12\n",
      "           3       0.57      0.29      0.38        14\n",
      "           4       0.33      0.11      0.17        18\n",
      "           5       0.80      0.44      0.57         9\n",
      "           6       0.30      0.38      0.33        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.45      0.39      0.38       107\n",
      "weighted avg       0.43      0.40      0.38       107\n",
      "\n",
      "Accuracy: 0.4019, Precision: 0.4255, Recall: 0.4019, F1: 0.3752\n",
      "\n",
      "Running for target_rcc_segments = 15\n",
      "Number of files processed: 535\n",
      "RCC-only shape: (535, 180)\n",
      "\n",
      "--- RCC with 15 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60        18\n",
      "           1       0.47      0.40      0.43        20\n",
      "           2       0.11      0.08      0.10        12\n",
      "           3       0.56      0.64      0.60        14\n",
      "           4       0.57      0.44      0.50        18\n",
      "           5       0.50      0.67      0.57         9\n",
      "           6       0.47      0.50      0.48        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.46      0.49      0.47       107\n",
      "weighted avg       0.47      0.49      0.48       107\n",
      "\n",
      "Accuracy: 0.4860, Precision: 0.4743, Recall: 0.4860, F1: 0.4756\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.94      0.62        18\n",
      "           1       0.50      0.60      0.55        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.67      0.29      0.40        14\n",
      "           4       0.75      0.33      0.46        18\n",
      "           5       0.75      1.00      0.86         9\n",
      "           6       0.38      0.38      0.38        16\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.54      0.52      0.48       107\n",
      "weighted avg       0.53      0.51      0.48       107\n",
      "\n",
      "Accuracy: 0.5140, Precision: 0.5313, Recall: 0.5140, F1: 0.4781\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.83      0.68        18\n",
      "           1       0.47      0.45      0.46        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.62      0.57      0.59        14\n",
      "           4       0.59      0.56      0.57        18\n",
      "           5       0.73      0.89      0.80         9\n",
      "           6       0.39      0.44      0.41        16\n",
      "\n",
      "    accuracy                           0.54       107\n",
      "   macro avg       0.53      0.55      0.52       107\n",
      "weighted avg       0.52      0.54      0.52       107\n",
      "\n",
      "Accuracy: 0.5421, Precision: 0.5218, Recall: 0.5421, F1: 0.5184\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59        18\n",
      "           1       0.47      0.35      0.40        20\n",
      "           2       0.17      0.17      0.17        12\n",
      "           3       0.43      0.43      0.43        14\n",
      "           4       0.40      0.33      0.36        18\n",
      "           5       0.38      0.56      0.45         9\n",
      "           6       0.36      0.50      0.42        16\n",
      "\n",
      "    accuracy                           0.41       107\n",
      "   macro avg       0.41      0.41      0.40       107\n",
      "weighted avg       0.42      0.41      0.41       107\n",
      "\n",
      "Accuracy: 0.4112, Precision: 0.4212, Recall: 0.4112, F1: 0.4109\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.83      0.57        18\n",
      "           1       0.42      0.40      0.41        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.44      0.29      0.35        14\n",
      "           4       0.67      0.22      0.33        18\n",
      "           5       0.67      0.44      0.53         9\n",
      "           6       0.38      0.69      0.49        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.48      0.42      0.40       107\n",
      "weighted avg       0.47      0.44      0.41       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4713, Recall: 0.4393, F1: 0.4064\n",
      "\n",
      "Running for target_rcc_segments = 20\n",
      "Number of files processed: 535\n",
      "RCC-only shape: (535, 240)\n",
      "\n",
      "--- RCC with 20 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.67      0.60        18\n",
      "           1       0.50      0.30      0.38        20\n",
      "           2       0.25      0.17      0.20        12\n",
      "           3       0.47      0.57      0.52        14\n",
      "           4       0.38      0.33      0.35        18\n",
      "           5       0.62      0.56      0.59         9\n",
      "           6       0.33      0.50      0.40        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.44      0.44      0.43       107\n",
      "weighted avg       0.44      0.44      0.43       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4403, Recall: 0.4393, F1: 0.4297\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.89      0.58        18\n",
      "           1       0.52      0.55      0.54        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.29      0.36        14\n",
      "           4       0.60      0.33      0.43        18\n",
      "           5       0.69      1.00      0.82         9\n",
      "           6       0.39      0.44      0.41        16\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.45      0.50      0.45       107\n",
      "weighted avg       0.45      0.50      0.45       107\n",
      "\n",
      "Accuracy: 0.4953, Precision: 0.4534, Recall: 0.4953, F1: 0.4482\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.61      0.51        18\n",
      "           1       0.47      0.35      0.40        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.33      0.43      0.38        14\n",
      "           4       0.55      0.33      0.41        18\n",
      "           5       0.64      1.00      0.78         9\n",
      "           6       0.45      0.56      0.50        16\n",
      "\n",
      "    accuracy                           0.46       107\n",
      "   macro avg       0.45      0.48      0.44       107\n",
      "weighted avg       0.45      0.46      0.43       107\n",
      "\n",
      "Accuracy: 0.4579, Precision: 0.4460, Recall: 0.4579, F1: 0.4341\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69        18\n",
      "           1       0.38      0.25      0.30        20\n",
      "           2       0.27      0.25      0.26        12\n",
      "           3       0.30      0.21      0.25        14\n",
      "           4       0.43      0.50      0.46        18\n",
      "           5       0.62      0.56      0.59         9\n",
      "           6       0.37      0.62      0.47        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.44      0.44      0.43       107\n",
      "weighted avg       0.44      0.44      0.43       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4405, Recall: 0.4393, F1: 0.4306\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.89      0.65        18\n",
      "           1       0.38      0.30      0.33        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.67      0.43      0.52        14\n",
      "           4       0.60      0.17      0.26        18\n",
      "           5       0.46      0.67      0.55         9\n",
      "           6       0.31      0.56      0.40        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.45      0.44      0.41       107\n",
      "weighted avg       0.46      0.44      0.40       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4583, Recall: 0.4393, F1: 0.4040\n",
      "\n",
      "Running for target_rcc_segments = 25\n",
      "Number of files processed: 535\n",
      "RCC-only shape: (535, 300)\n",
      "\n",
      "--- RCC with 25 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.56      0.51        18\n",
      "           1       0.50      0.30      0.38        20\n",
      "           2       0.20      0.08      0.12        12\n",
      "           3       0.43      0.43      0.43        14\n",
      "           4       0.42      0.56      0.48        18\n",
      "           5       0.43      0.67      0.52         9\n",
      "           6       0.41      0.44      0.42        16\n",
      "\n",
      "    accuracy                           0.43       107\n",
      "   macro avg       0.41      0.43      0.41       107\n",
      "weighted avg       0.42      0.43      0.41       107\n",
      "\n",
      "Accuracy: 0.4299, Precision: 0.4198, Recall: 0.4299, F1: 0.4131\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.89      0.57        18\n",
      "           1       0.52      0.60      0.56        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.21      0.30        14\n",
      "           4       0.56      0.28      0.37        18\n",
      "           5       0.75      1.00      0.86         9\n",
      "           6       0.39      0.44      0.41        16\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.45      0.49      0.44       107\n",
      "weighted avg       0.45      0.49      0.44       107\n",
      "\n",
      "Accuracy: 0.4860, Precision: 0.4485, Recall: 0.4860, F1: 0.4357\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.72      0.65        18\n",
      "           1       0.53      0.50      0.51        20\n",
      "           2       0.60      0.25      0.35        12\n",
      "           3       0.58      0.50      0.54        14\n",
      "           4       0.56      0.56      0.56        18\n",
      "           5       0.73      0.89      0.80         9\n",
      "           6       0.45      0.56      0.50        16\n",
      "\n",
      "    accuracy                           0.56       107\n",
      "   macro avg       0.58      0.57      0.56       107\n",
      "weighted avg       0.56      0.56      0.55       107\n",
      "\n",
      "Accuracy: 0.5607, Precision: 0.5633, Recall: 0.5607, F1: 0.5507\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.61      0.58        18\n",
      "           1       0.50      0.20      0.29        20\n",
      "           2       0.17      0.08      0.11        12\n",
      "           3       0.35      0.50      0.41        14\n",
      "           4       0.44      0.44      0.44        18\n",
      "           5       0.55      0.67      0.60         9\n",
      "           6       0.42      0.62      0.50        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.42      0.45      0.42       107\n",
      "weighted avg       0.43      0.44      0.42       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4334, Recall: 0.4393, F1: 0.4171\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.72      0.60        18\n",
      "           1       0.29      0.40      0.33        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.25      0.14      0.18        14\n",
      "           4       0.50      0.17      0.25        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.35      0.56      0.43        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.43      0.41      0.37       107\n",
      "weighted avg       0.41      0.40      0.37       107\n",
      "\n",
      "Accuracy: 0.4019, Precision: 0.4146, Recall: 0.4019, F1: 0.3660\n",
      "\n",
      "Running for target_rcc_segments = 30\n",
      "Number of files processed: 535\n",
      "RCC-only shape: (535, 360)\n",
      "\n",
      "--- RCC with 30 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.61      0.55        18\n",
      "           1       0.45      0.45      0.45        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.40      0.57      0.47        14\n",
      "           4       0.53      0.50      0.51        18\n",
      "           5       0.57      0.44      0.50         9\n",
      "           6       0.35      0.38      0.36        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.44      0.43      0.42       107\n",
      "weighted avg       0.44      0.45      0.44       107\n",
      "\n",
      "Accuracy: 0.4486, Precision: 0.4385, Recall: 0.4486, F1: 0.4352\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.89      0.56        18\n",
      "           1       0.39      0.35      0.37        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.75      0.21      0.33        14\n",
      "           4       0.67      0.33      0.44        18\n",
      "           5       0.64      1.00      0.78         9\n",
      "           6       0.30      0.44      0.36        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.45      0.46      0.41       107\n",
      "weighted avg       0.45      0.45      0.40       107\n",
      "\n",
      "Accuracy: 0.4486, Precision: 0.4516, Recall: 0.4486, F1: 0.4012\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59        18\n",
      "           1       0.50      0.40      0.44        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.47      0.57      0.52        14\n",
      "           4       0.54      0.39      0.45        18\n",
      "           5       0.57      0.89      0.70         9\n",
      "           6       0.50      0.56      0.53        16\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.44      0.50      0.46       107\n",
      "weighted avg       0.45      0.50      0.46       107\n",
      "\n",
      "Accuracy: 0.4953, Precision: 0.4526, Recall: 0.4953, F1: 0.4637\n",
      "\n",
      "Training and evaluating: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59        18\n",
      "           1       0.64      0.35      0.45        20\n",
      "           2       0.12      0.08      0.10        12\n",
      "           3       0.40      0.43      0.41        14\n",
      "           4       0.50      0.56      0.53        18\n",
      "           5       0.64      0.78      0.70         9\n",
      "           6       0.39      0.56      0.46        16\n",
      "\n",
      "    accuracy                           0.48       107\n",
      "   macro avg       0.47      0.48      0.46       107\n",
      "weighted avg       0.48      0.48      0.47       107\n",
      "\n",
      "Accuracy: 0.4766, Precision: 0.4788, Recall: 0.4766, F1: 0.4662\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.72      0.58        18\n",
      "           1       0.38      0.50      0.43        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.38      0.21      0.27        14\n",
      "           4       0.57      0.22      0.32        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.42      0.69      0.52        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.40      0.45      0.40       107\n",
      "weighted avg       0.41      0.45      0.40       107\n",
      "\n",
      "Accuracy: 0.4486, Precision: 0.4104, Recall: 0.4486, F1: 0.4024\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>▁▁▇▇▁█</td></tr><tr><td>KNN_F1</td><td>▁▄██▃█</td></tr><tr><td>KNN_Precision</td><td>▁▅█▇▅▅</td></tr><tr><td>KNN_Recall</td><td>▁▁▇▇▁█</td></tr><tr><td>LogisticRegression_Accuracy</td><td>█▅▁▂▂▄</td></tr><tr><td>LogisticRegression_F1</td><td>█▅▁▂▁▄</td></tr><tr><td>LogisticRegression_Precision</td><td>█▆▁▂▂▄</td></tr><tr><td>LogisticRegression_Recall</td><td>█▅▁▂▂▄</td></tr><tr><td>RandomForest_Accuracy</td><td>█▇▅▄▃▁</td></tr><tr><td>RandomForest_F1</td><td>█▆▄▃▃▁</td></tr><tr><td>RandomForest_Precision</td><td>█▆▅▁▁▁</td></tr><tr><td>RandomForest_Recall</td><td>█▇▅▄▃▁</td></tr><tr><td>SVM_Accuracy</td><td>▅█▄▁▁▂</td></tr><tr><td>SVM_F1</td><td>▆█▄▂▁▂</td></tr><tr><td>SVM_Precision</td><td>▅█▄▂▁▂</td></tr><tr><td>SVM_Recall</td><td>▅█▄▁▁▂</td></tr><tr><td>XGBoost_Accuracy</td><td>▆█▆▁▇▃</td></tr><tr><td>XGBoost_F1</td><td>▆█▅▁▇▂</td></tr><tr><td>XGBoost_Precision</td><td>▆█▅▁▇▁</td></tr><tr><td>XGBoost_Recall</td><td>▆█▆▁▇▃</td></tr><tr><td>feature_dim</td><td>▁▂▄▅▇█</td></tr><tr><td>rcc_segments</td><td>▁▂▄▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>0.4486</td></tr><tr><td>KNN_F1</td><td>0.40238</td></tr><tr><td>KNN_Precision</td><td>0.41041</td></tr><tr><td>KNN_Recall</td><td>0.4486</td></tr><tr><td>LogisticRegression_Accuracy</td><td>0.47664</td></tr><tr><td>LogisticRegression_F1</td><td>0.46623</td></tr><tr><td>LogisticRegression_Precision</td><td>0.47885</td></tr><tr><td>LogisticRegression_Recall</td><td>0.47664</td></tr><tr><td>RCC_n10_best_accuracy</td><td>0.58879</td></tr><tr><td>RCC_n15_best_accuracy</td><td>0.54206</td></tr><tr><td>RCC_n20_best_accuracy</td><td>0.49533</td></tr><tr><td>RCC_n25_best_accuracy</td><td>0.56075</td></tr><tr><td>RCC_n30_best_accuracy</td><td>0.49533</td></tr><tr><td>RCC_n5_best_accuracy</td><td>0.57944</td></tr><tr><td>RandomForest_Accuracy</td><td>0.4486</td></tr><tr><td>RandomForest_F1</td><td>0.40119</td></tr><tr><td>RandomForest_Precision</td><td>0.45157</td></tr><tr><td>RandomForest_Recall</td><td>0.4486</td></tr><tr><td>SVM_Accuracy</td><td>0.4486</td></tr><tr><td>SVM_F1</td><td>0.43517</td></tr><tr><td>SVM_Precision</td><td>0.4385</td></tr><tr><td>SVM_Recall</td><td>0.4486</td></tr><tr><td>XGBoost_Accuracy</td><td>0.49533</td></tr><tr><td>XGBoost_F1</td><td>0.46366</td></tr><tr><td>XGBoost_Precision</td><td>0.45256</td></tr><tr><td>XGBoost_Recall</td><td>0.49533</td></tr><tr><td>feature_dim</td><td>360</td></tr><tr><td>feature_type</td><td>RCC</td></tr><tr><td>rcc_segments</td><td>30</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-rcc-classification</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/26ilsodu' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/26ilsodu</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_230648-26ilsodu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"emotion-recognition\", name=\"ssp-rcc-classification\")\n",
    "\n",
    "# Experiment with different segment values for RCC features\n",
    "rcc_segment_values = np.arange(5, 16, 2)  # Try different segment values from 5 to 45\n",
    "labels_csv_path = \"./EmoDB_dataset/emotion_mapping_detailed.csv\"\n",
    "labels = pd.read_csv(labels_csv_path)\n",
    "\n",
    "for n in rcc_segment_values:\n",
    "    print(f\"\\nRunning for target_rcc_segments = {n}\")\n",
    "    \n",
    "    # Extract RCC features with the current number of segments\n",
    "    features = process_directory_rcc(directory, target_rcc_segments=n)\n",
    "    print(f\"Number of files processed: {len(features)}\")\n",
    "    \n",
    "    # Prepare feature sets\n",
    "    X_rcc, y_rcc = prepare_rcc_dataset(features, labels)\n",
    "    print(\"RCC-only shape:\", X_rcc.shape)\n",
    "    \n",
    "    # Train and evaluate classifiers, logging metrics to wandb\n",
    "    print(f\"\\n--- RCC with {n} segments ---\")\n",
    "    metrics = train_and_evaluate(X_rcc, y_rcc)\n",
    "    \n",
    "    # Log metrics to wandb with current segment value\n",
    "    log_data = {\n",
    "        \"rcc_segments\": n,\n",
    "        \"feature_type\": \"RCC\",\n",
    "        \"feature_dim\": X_rcc.shape[1],\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    wandb.log(log_data)\n",
    "    \n",
    "    # Add summary for easy comparison\n",
    "    wandb.run.summary[f\"RCC_n{n}_best_accuracy\"] = max([\n",
    "        metrics.get(\"SVM_Accuracy\", 0),\n",
    "        metrics.get(\"RandomForest_Accuracy\", 0),\n",
    "        metrics.get(\"XGBoost_Accuracy\", 0),\n",
    "        metrics.get(\"LogisticRegression_Accuracy\", 0),\n",
    "        metrics.get(\"KNN_Accuracy\", 0)\n",
    "    ])\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LP Residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "def compute_lp_residual_energy(frame: np.ndarray, order: int = 12) -> float:\n",
    "    \"\"\"\n",
    "    Compute the Linear Prediction (LP) residual energy of a signal frame using librosa.\n",
    "\n",
    "    Parameters:\n",
    "    frame (np.ndarray): The input frame of the signal.\n",
    "    order (int): The order of the LPC analysis (default is 12).\n",
    "\n",
    "    Returns:\n",
    "    float: The energy of the LP residual signal.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Step 1: LPC Analysis using librosa to compute LPC coefficients\n",
    "        a = librosa.lpc(frame, order=order)  # LPC coefficients (a[0] is the gain)\n",
    "\n",
    "        # Step 2: Compute the residual signal by filtering the frame using LPC coefficients\n",
    "        residual = lfilter(a, [1.0], frame)\n",
    "\n",
    "        # Step 3: Compute the energy of the residual signal (sum of squared values)\n",
    "        residual_energy = np.sum(residual ** 2)\n",
    "\n",
    "        return residual_energy\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error computing LP residual energy: {e}\")\n",
    "        return 0.0  # Return zero in case of error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lp_features(file_path: str,\n",
    "                        frame_size: float = 0.025,\n",
    "                        frame_stride: float = 0.01,\n",
    "                        target_lp_segments: int = 100,\n",
    "                        lp_order: int = 12) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts Linear Prediction (LP) residual energy framewise then condenses \n",
    "    the features into a fixed-length feature matrix via average pooling.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): Path to the audio file.\n",
    "        frame_size (float): Frame duration in seconds.\n",
    "        frame_stride (float): Step between successive frames in seconds.\n",
    "        target_lp_segments (int): Desired number of pooled segments for LP residual features.\n",
    "        lp_order (int): Order of the LP analysis.\n",
    "    \n",
    "    Returns:\n",
    "        np.ndarray: Pooled LP residual energies with shape (target_lp_segments, 1).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signal, sr = librosa.load(file_path, sr=None)\n",
    "        frame_length = int(frame_size * sr)\n",
    "        hop_length = int(frame_stride * sr)\n",
    "        \n",
    "        # Frame the signal: shape (number_of_frames, frame_length)\n",
    "        frames = librosa.util.frame(signal, frame_length=frame_length, hop_length=hop_length).T\n",
    "\n",
    "        lp_list = []\n",
    "        \n",
    "        for frame in frames:\n",
    "            # Apply windowing\n",
    "            frame = frame * np.hamming(len(frame))\n",
    "            \n",
    "            # LP residual energy extraction: using librosa.lpc for LPC coefficients\n",
    "            try:\n",
    "                a_lp = librosa.lpc(frame, order=lp_order) \n",
    "                residual_lp = lfilter(a_lp, [1.0], frame)\n",
    "                lp_energy = np.sum(residual_lp ** 2)\n",
    "            except Exception as ex:\n",
    "                print(f\"Error in LP energy computation for frame: {ex}\")\n",
    "                lp_energy = 0.0\n",
    "            \n",
    "            lp_list.append([lp_energy])  # Keep as list for 2D array\n",
    "\n",
    "        lp_array = np.array(lp_list)  # shape: (num_frames, 1)\n",
    "        \n",
    "        # Average pool features to desired length\n",
    "        lp_segments = np.array_split(lp_array, target_lp_segments, axis=0)\n",
    "        lp_pooled = np.array([np.mean(seg, axis=0) for seg in lp_segments])\n",
    "        \n",
    "        return lp_pooled\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path} for LP: {e}\")\n",
    "        return np.zeros((target_lp_segments, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_directory_lp(directory: str,\n",
    "                         frame_size: float = 0.025,\n",
    "                         frame_stride: float = 0.01,\n",
    "                         target_lp_segments: int = 100,\n",
    "                         lp_order: int = 12) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Processes all .wav files in the directory and extracts LP residual features.\n",
    "\n",
    "    Parameters:\n",
    "        directory (str): Path to the directory containing .wav files.\n",
    "        frame_size (float): Frame duration in seconds.\n",
    "        frame_stride (float): Step between successive frames in seconds.\n",
    "        target_lp_segments (int): Desired number of pooled segments for LP residual features.\n",
    "        lp_order (int): Order of the LP analysis.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping of filename to flattened LP feature vectors.\n",
    "    \"\"\"\n",
    "    feature_vectors = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            try:\n",
    "                lp_features = extract_lp_features(\n",
    "                    file_path,\n",
    "                    frame_size=frame_size,\n",
    "                    frame_stride=frame_stride,\n",
    "                    target_lp_segments=target_lp_segments,\n",
    "                    lp_order=lp_order\n",
    "                )\n",
    "                lp_flat = lp_features.flatten()  # Shape: (target_lp_segments,)\n",
    "                feature_vectors[filename] = lp_flat\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing LP for {file_path}: {e}\")\n",
    "\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_lp_dataset(features: dict, labels: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Prepares LP feature set for classification.\n",
    "\n",
    "    Parameters:\n",
    "        features (dict): Dictionary mapping filenames to LP feature vectors.\n",
    "        labels (pd.DataFrame): DataFrame containing emotion labels.\n",
    "    \n",
    "    Returns:\n",
    "        tuple:\n",
    "            np.ndarray: LP features.\n",
    "            np.ndarray: Emotion labels.\n",
    "    \"\"\"\n",
    "    X_lp, y = [], []\n",
    "\n",
    "    for _, row in labels.iterrows():\n",
    "        file_id = row['Filename']\n",
    "        if file_id in features:\n",
    "            # Direct access to feature vector (no nested dictionary)\n",
    "            X_lp.append(features[file_id])\n",
    "            y.append(int(row['EmotionNumeric']))\n",
    "\n",
    "    return np.array(X_lp), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>▂██▆▁█</td></tr><tr><td>KNN_F1</td><td>▃▆█▅▁▇</td></tr><tr><td>KNN_Precision</td><td>▆▄█▄▁▇</td></tr><tr><td>KNN_Recall</td><td>▂██▆▁█</td></tr><tr><td>LogisticRegression_Accuracy</td><td>▂▁▆▅▃█</td></tr><tr><td>LogisticRegression_F1</td><td>▁▂▆▆▃█</td></tr><tr><td>LogisticRegression_Precision</td><td>▁▂█▆▂▆</td></tr><tr><td>LogisticRegression_Recall</td><td>▂▁▆▅▃█</td></tr><tr><td>RandomForest_Accuracy</td><td>▁▃▃▄██</td></tr><tr><td>RandomForest_F1</td><td>▁▃▂▂██</td></tr><tr><td>RandomForest_Precision</td><td>▄▅▄▁█▆</td></tr><tr><td>RandomForest_Recall</td><td>▁▃▃▄██</td></tr><tr><td>SVM_Accuracy</td><td>▅▁▄▅▇█</td></tr><tr><td>SVM_F1</td><td>▁▁▃▆██</td></tr><tr><td>SVM_Precision</td><td>▁▄▂▅▆█</td></tr><tr><td>SVM_Recall</td><td>▅▁▄▅▇█</td></tr><tr><td>XGBoost_Accuracy</td><td>▁▃█▆▄▅</td></tr><tr><td>XGBoost_F1</td><td>▁▄█▆▄▅</td></tr><tr><td>XGBoost_Precision</td><td>▁▅█▆▄▄</td></tr><tr><td>XGBoost_Recall</td><td>▁▃█▆▄▅</td></tr><tr><td>feature_dim</td><td>▁▂▄▅▇█</td></tr><tr><td>lp_segments</td><td>▁▂▄▅▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>0.30841</td></tr><tr><td>KNN_F1</td><td>0.26736</td></tr><tr><td>KNN_Precision</td><td>0.321</td></tr><tr><td>KNN_Recall</td><td>0.30841</td></tr><tr><td>LP_n100_best_accuracy</td><td>0.51402</td></tr><tr><td>LP_n120_best_accuracy</td><td>0.51402</td></tr><tr><td>LP_n20_best_accuracy</td><td>0.43925</td></tr><tr><td>LP_n40_best_accuracy</td><td>0.45794</td></tr><tr><td>LP_n60_best_accuracy</td><td>0.5514</td></tr><tr><td>LP_n80_best_accuracy</td><td>0.50467</td></tr><tr><td>LogisticRegression_Accuracy</td><td>0.35514</td></tr><tr><td>LogisticRegression_F1</td><td>0.32037</td></tr><tr><td>LogisticRegression_Precision</td><td>0.37934</td></tr><tr><td>LogisticRegression_Recall</td><td>0.35514</td></tr><tr><td>RandomForest_Accuracy</td><td>0.51402</td></tr><tr><td>RandomForest_F1</td><td>0.45375</td></tr><tr><td>RandomForest_Precision</td><td>0.45847</td></tr><tr><td>RandomForest_Recall</td><td>0.51402</td></tr><tr><td>SVM_Accuracy</td><td>0.30841</td></tr><tr><td>SVM_F1</td><td>0.26579</td></tr><tr><td>SVM_Precision</td><td>0.3794</td></tr><tr><td>SVM_Recall</td><td>0.30841</td></tr><tr><td>XGBoost_Accuracy</td><td>0.47664</td></tr><tr><td>XGBoost_F1</td><td>0.45002</td></tr><tr><td>XGBoost_Precision</td><td>0.45547</td></tr><tr><td>XGBoost_Recall</td><td>0.47664</td></tr><tr><td>feature_dim</td><td>120</td></tr><tr><td>feature_type</td><td>LP_Residual</td></tr><tr><td>lp_segments</td><td>120</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-lp-classification</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/bypdl5u0' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/bypdl5u0</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_231133-bypdl5u0\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\College\\4-2\\SSP\\SSP_Project\\newProject\\EmotionRecognition_SSP\\wandb\\run-20250421_231508-22en99g3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/22en99g3' target=\"_blank\">ssp-lp-classification</a></strong> to <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/22en99g3' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/22en99g3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for target_lp_segments = 20\n",
      "Number of files processed: 535\n",
      "LP-only shape: (535, 20)\n",
      "\n",
      "--- LP Residual with 20 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.78      0.42        18\n",
      "           1       0.57      0.20      0.30        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.33      0.11      0.17         9\n",
      "           6       0.25      0.75      0.38        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.21      0.26      0.18       107\n",
      "weighted avg       0.22      0.29      0.20       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.2213, Recall: 0.2897, F1: 0.1968\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.83      0.50        18\n",
      "           1       0.59      0.50      0.54        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.36      0.42        14\n",
      "           4       0.50      0.11      0.18        18\n",
      "           5       0.64      0.78      0.70         9\n",
      "           6       0.40      0.50      0.44        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.43      0.44      0.40       107\n",
      "weighted avg       0.43      0.44      0.40       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4329, Recall: 0.4393, F1: 0.3956\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.78      0.51        18\n",
      "           1       0.50      0.40      0.44        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.56      0.36      0.43        14\n",
      "           4       0.33      0.17      0.22        18\n",
      "           5       0.60      0.67      0.63         9\n",
      "           6       0.29      0.38      0.32        16\n",
      "\n",
      "    accuracy                           0.39       107\n",
      "   macro avg       0.38      0.39      0.37       107\n",
      "weighted avg       0.38      0.39      0.36       107\n",
      "\n",
      "Accuracy: 0.3925, Precision: 0.3791, Recall: 0.3925, F1: 0.3646\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.72      0.35        18\n",
      "           1       0.64      0.35      0.45        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.33      0.14      0.20        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.50      0.11      0.18         9\n",
      "           6       0.31      0.56      0.40        16\n",
      "\n",
      "    accuracy                           0.30       107\n",
      "   macro avg       0.29      0.27      0.23       107\n",
      "weighted avg       0.29      0.30      0.24       107\n",
      "\n",
      "Accuracy: 0.2991, Precision: 0.2894, Recall: 0.2991, F1: 0.2440\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.72      0.45        18\n",
      "           1       0.26      0.35      0.30        20\n",
      "           2       1.00      0.08      0.15        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.25      0.06      0.09        18\n",
      "           5       0.33      0.22      0.27         9\n",
      "           6       0.17      0.25      0.21        16\n",
      "\n",
      "    accuracy                           0.26       107\n",
      "   macro avg       0.33      0.24      0.21       107\n",
      "weighted avg       0.31      0.26      0.22       107\n",
      "\n",
      "Accuracy: 0.2617, Precision: 0.3114, Recall: 0.2617, F1: 0.2167\n",
      "\n",
      "Running for target_lp_segments = 40\n",
      "Number of files processed: 535\n",
      "LP-only shape: (535, 40)\n",
      "\n",
      "--- LP Residual with 40 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.67      0.39        18\n",
      "           1       0.50      0.10      0.17        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.20      0.07      0.11        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.50      0.11      0.18         9\n",
      "           6       0.23      0.69      0.35        16\n",
      "\n",
      "    accuracy                           0.26       107\n",
      "   macro avg       0.32      0.25      0.19       107\n",
      "weighted avg       0.30      0.26      0.19       107\n",
      "\n",
      "Accuracy: 0.2617, Precision: 0.2986, Recall: 0.2617, F1: 0.1936\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.83      0.60        18\n",
      "           1       0.62      0.40      0.48        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.47      0.50      0.48        14\n",
      "           4       0.60      0.17      0.26        18\n",
      "           5       0.50      0.78      0.61         9\n",
      "           6       0.33      0.56      0.42        16\n",
      "\n",
      "    accuracy                           0.46       107\n",
      "   macro avg       0.43      0.46      0.41       107\n",
      "weighted avg       0.45      0.46      0.41       107\n",
      "\n",
      "Accuracy: 0.4579, Precision: 0.4478, Recall: 0.4579, F1: 0.4124\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.72      0.59        18\n",
      "           1       0.64      0.35      0.45        20\n",
      "           2       0.20      0.17      0.18        12\n",
      "           3       0.33      0.36      0.34        14\n",
      "           4       0.60      0.17      0.26        18\n",
      "           5       0.54      0.78      0.64         9\n",
      "           6       0.41      0.69      0.51        16\n",
      "\n",
      "    accuracy                           0.45       107\n",
      "   macro avg       0.46      0.46      0.43       107\n",
      "weighted avg       0.48      0.45      0.42       107\n",
      "\n",
      "Accuracy: 0.4486, Precision: 0.4762, Recall: 0.4486, F1: 0.4232\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.67      0.35        18\n",
      "           1       0.75      0.30      0.43        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.25      0.14      0.18        14\n",
      "           4       0.20      0.06      0.09        18\n",
      "           5       0.20      0.11      0.14         9\n",
      "           6       0.31      0.56      0.40        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.28      0.26      0.23       107\n",
      "weighted avg       0.31      0.29      0.25       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.3101, Recall: 0.2897, F1: 0.2497\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.61      0.44        18\n",
      "           1       0.41      0.70      0.52        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.20      0.14      0.17        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.50      0.33      0.40         9\n",
      "           6       0.11      0.12      0.11        16\n",
      "\n",
      "    accuracy                           0.31       107\n",
      "   macro avg       0.26      0.29      0.25       107\n",
      "weighted avg       0.25      0.31      0.26       107\n",
      "\n",
      "Accuracy: 0.3084, Precision: 0.2468, Recall: 0.3084, F1: 0.2575\n",
      "\n",
      "Running for target_lp_segments = 60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mRunning for target_lp_segments = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Extract LP features with the current number of segments\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m features = \u001b[43mprocess_directory_lp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_lp_segments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNumber of files processed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Prepare feature sets\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mprocess_directory_lp\u001b[39m\u001b[34m(directory, frame_size, frame_stride, target_lp_segments, lp_order)\u001b[39m\n\u001b[32m     23\u001b[39m file_path = os.path.join(directory, filename)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     lp_features = \u001b[43mextract_lp_features\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_stride\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframe_stride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_lp_segments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_lp_segments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlp_order\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlp_order\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     lp_flat = lp_features.flatten()  \u001b[38;5;66;03m# Shape: (target_lp_segments,)\u001b[39;00m\n\u001b[32m     33\u001b[39m     feature_vectors[filename] = lp_flat\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mextract_lp_features\u001b[39m\u001b[34m(file_path, frame_size, frame_stride, target_lp_segments, lp_order)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     36\u001b[39m     a_lp = librosa.lpc(frame, order=lp_order) \n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     residual_lp = \u001b[43mlfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_lp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     lp_energy = np.sum(residual_lp ** \u001b[32m2\u001b[39m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:2158\u001b[39m, in \u001b[36mlfilter\u001b[39m\u001b[34m(b, a, x, axis, zi)\u001b[39m\n\u001b[32m   2155\u001b[39m b /= a[\u001b[32m0\u001b[39m]\n\u001b[32m   2156\u001b[39m x = np.asarray(x, dtype=dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m out_full = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2159\u001b[39m ind = out_full.ndim * [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)]\n\u001b[32m   2160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m zi \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\numpy\\lib\\_shape_base_impl.py:393\u001b[39m, in \u001b[36mapply_along_axis\u001b[39m\u001b[34m(func1d, axis, arr, *args, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    390\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    391\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mCannot apply_along_axis when any iteration dimensions are 0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    392\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m393\u001b[39m res = asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind0\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    395\u001b[39m \u001b[38;5;66;03m# build a buffer for storing evaluations of func1d.\u001b[39;00m\n\u001b[32m    396\u001b[39m \u001b[38;5;66;03m# remove the requested axis, and add the new ones on the end.\u001b[39;00m\n\u001b[32m    397\u001b[39m \u001b[38;5;66;03m# laid out so that each write is contiguous.\u001b[39;00m\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# for a tuple index inds, buff[inds] = func1d(inarr_view[inds])\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, matrix):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\scipy\\signal\\_signaltools.py:2158\u001b[39m, in \u001b[36mlfilter.<locals>.<lambda>\u001b[39m\u001b[34m(y)\u001b[39m\n\u001b[32m   2155\u001b[39m b /= a[\u001b[32m0\u001b[39m]\n\u001b[32m   2156\u001b[39m x = np.asarray(x, dtype=dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2158\u001b[39m out_full = np.apply_along_axis(\u001b[38;5;28;01mlambda\u001b[39;00m y: \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m, axis, x)\n\u001b[32m   2159\u001b[39m ind = out_full.ndim * [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)]\n\u001b[32m   2160\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m zi \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sanni\\miniconda3\\envs\\coding\\Lib\\site-packages\\numpy\\_core\\numeric.py:889\u001b[39m, in \u001b[36mconvolve\u001b[39m\u001b[34m(a, v, mode)\u001b[39m\n\u001b[32m    887\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(v) == \u001b[32m0\u001b[39m:\n\u001b[32m    888\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mv cannot be empty\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmultiarray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcorrelate\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"emotion-recognition\", name=\"ssp-lp-classification\")\n",
    "\n",
    "# Experiment with different segment values for LP features\n",
    "lp_segment_values = np.arange(20, 120, 15)  # Try different segment values from 20 to 140\n",
    "labels = pd.read_csv(labels_csv_path)\n",
    "\n",
    "for n in lp_segment_values:\n",
    "    print(f\"\\nRunning for target_lp_segments = {n}\")\n",
    "    \n",
    "    # Extract LP features with the current number of segments\n",
    "    features = process_directory_lp(directory, target_lp_segments=n)\n",
    "    print(f\"Number of files processed: {len(features)}\")\n",
    "    \n",
    "    # Prepare feature sets\n",
    "    X_lp, y_lp = prepare_lp_dataset(features, labels)\n",
    "    print(\"LP-only shape:\", X_lp.shape)\n",
    "    \n",
    "    # Train and evaluate classifiers, logging metrics to wandb\n",
    "    print(f\"\\n--- LP Residual with {n} segments ---\")\n",
    "    metrics = train_and_evaluate(X_lp, y_lp)\n",
    "    \n",
    "    # Log metrics to wandb with current segment value\n",
    "    log_data = {\n",
    "        \"lp_segments\": n,\n",
    "        \"feature_type\": \"LP_Residual\",\n",
    "        \"feature_dim\": X_lp.shape[1],\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    wandb.log(log_data)\n",
    "    \n",
    "    # Add summary for easy comparison\n",
    "    wandb.run.summary[f\"LP_n{n}_best_accuracy\"] = max([\n",
    "        metrics.get(\"SVM_Accuracy\", 0),\n",
    "        metrics.get(\"RandomForest_Accuracy\", 0),\n",
    "        metrics.get(\"XGBoost_Accuracy\", 0),\n",
    "        metrics.get(\"LogisticRegression_Accuracy\", 0),\n",
    "        metrics.get(\"KNN_Accuracy\", 0)\n",
    "    ])\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GVV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import scipy.signal\n",
    "from typing import Dict\n",
    "\n",
    "def extract_gvv_features(file_path: str, frame_size: float = 0.025, frame_stride: float = 0.01, n_segments: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extracts GVV features from an audio file using a simplified IAIF approach.\n",
    "    The features are averaged over time into an n x 1 feature matrix.\n",
    "\n",
    "    Returns:\n",
    "      np.ndarray: A (n_segments, 1) array of GVV energy values.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        signal, sample_rate = librosa.load(file_path, sr=None)\n",
    "        frame_length = int(frame_size * sample_rate)\n",
    "        hop_length = int(frame_stride * sample_rate)\n",
    "\n",
    "        # Pre-emphasis\n",
    "        pre_emphasis = 0.97\n",
    "        emphasized_signal = np.append(signal[0], signal[1:] - pre_emphasis * signal[:-1])\n",
    "\n",
    "        # LPC Analysis\n",
    "        lpc_order = 16\n",
    "        lpc_coeffs = librosa.lpc(emphasized_signal, order=lpc_order)\n",
    "\n",
    "        # Inverse filtering (glottal excitation)\n",
    "        glottal_source = scipy.signal.lfilter(lpc_coeffs, [1.0], emphasized_signal)\n",
    "\n",
    "        # Frame the glottal source signal\n",
    "        frames = librosa.util.frame(glottal_source, frame_length=frame_length, hop_length=hop_length).T\n",
    "\n",
    "        # Energy per frame\n",
    "        frame_energies = np.sum(frames ** 2, axis=1)\n",
    "\n",
    "        # Normalize energies\n",
    "        frame_energies -= np.mean(frame_energies)\n",
    "        frame_energies /= (np.std(frame_energies) + 1e-6)\n",
    "\n",
    "        # Segment pooling\n",
    "        segments = np.array_split(frame_energies, n_segments)\n",
    "        pooled_features = np.array([np.mean(seg) for seg in segments]).reshape(-1, 1)\n",
    "\n",
    "        return pooled_features\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {e}\")\n",
    "        return np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory_gvv(directory: str, n_segments: int = 10) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extracts GVV features from all .wav files in the directory.\n",
    "    \"\"\"\n",
    "    feature_vectors = {}\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.wav'):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            features = extract_gvv_features(file_path, n_segments=n_segments)\n",
    "            if features.size > 0:\n",
    "                feature_vectors[filename] = features.flatten()  # Flatten for classifier input\n",
    "    return feature_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>▁█</td></tr><tr><td>KNN_F1</td><td>▁█</td></tr><tr><td>KNN_Precision</td><td>█▁</td></tr><tr><td>KNN_Recall</td><td>▁█</td></tr><tr><td>LogisticRegression_Accuracy</td><td>█▁</td></tr><tr><td>LogisticRegression_F1</td><td>▁█</td></tr><tr><td>LogisticRegression_Precision</td><td>▁█</td></tr><tr><td>LogisticRegression_Recall</td><td>█▁</td></tr><tr><td>RandomForest_Accuracy</td><td>▁█</td></tr><tr><td>RandomForest_F1</td><td>▁█</td></tr><tr><td>RandomForest_Precision</td><td>▁█</td></tr><tr><td>RandomForest_Recall</td><td>▁█</td></tr><tr><td>SVM_Accuracy</td><td>█▁</td></tr><tr><td>SVM_F1</td><td>█▁</td></tr><tr><td>SVM_Precision</td><td>▁█</td></tr><tr><td>SVM_Recall</td><td>█▁</td></tr><tr><td>XGBoost_Accuracy</td><td>▁█</td></tr><tr><td>XGBoost_F1</td><td>▁█</td></tr><tr><td>XGBoost_Precision</td><td>▁█</td></tr><tr><td>XGBoost_Recall</td><td>▁█</td></tr><tr><td>feature_dim</td><td>▁█</td></tr><tr><td>lp_segments</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>0.30841</td></tr><tr><td>KNN_F1</td><td>0.2575</td></tr><tr><td>KNN_Precision</td><td>0.24679</td></tr><tr><td>KNN_Recall</td><td>0.30841</td></tr><tr><td>LP_n20_best_accuracy</td><td>0.43925</td></tr><tr><td>LP_n40_best_accuracy</td><td>0.45794</td></tr><tr><td>LogisticRegression_Accuracy</td><td>0.28972</td></tr><tr><td>LogisticRegression_F1</td><td>0.24973</td></tr><tr><td>LogisticRegression_Precision</td><td>0.31015</td></tr><tr><td>LogisticRegression_Recall</td><td>0.28972</td></tr><tr><td>RandomForest_Accuracy</td><td>0.45794</td></tr><tr><td>RandomForest_F1</td><td>0.4124</td></tr><tr><td>RandomForest_Precision</td><td>0.44777</td></tr><tr><td>RandomForest_Recall</td><td>0.45794</td></tr><tr><td>SVM_Accuracy</td><td>0.26168</td></tr><tr><td>SVM_F1</td><td>0.19358</td></tr><tr><td>SVM_Precision</td><td>0.29863</td></tr><tr><td>SVM_Recall</td><td>0.26168</td></tr><tr><td>XGBoost_Accuracy</td><td>0.4486</td></tr><tr><td>XGBoost_F1</td><td>0.42324</td></tr><tr><td>XGBoost_Precision</td><td>0.47625</td></tr><tr><td>XGBoost_Recall</td><td>0.4486</td></tr><tr><td>feature_dim</td><td>40</td></tr><tr><td>feature_type</td><td>LP_Residual</td></tr><tr><td>lp_segments</td><td>40</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-lp-classification</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/22en99g3' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/22en99g3</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_231508-22en99g3\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\College\\4-2\\SSP\\SSP_Project\\newProject\\EmotionRecognition_SSP\\wandb\\run-20250421_231606-aix4js6v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/aix4js6v' target=\"_blank\">ssp-gvv-classification</a></strong> to <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/aix4js6v' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/aix4js6v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running for n_segments = 5\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 5)\n",
      "\n",
      "--- GVV with 5 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.83      0.35        18\n",
      "           1       0.44      0.60      0.51        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.30      0.33      0.32         9\n",
      "           6       0.50      0.06      0.11        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.21      0.26      0.18       107\n",
      "weighted avg       0.22      0.29      0.20       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.2202, Recall: 0.2897, F1: 0.1973\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.67      0.43        18\n",
      "           1       0.39      0.35      0.37        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.50      0.14      0.22        14\n",
      "           4       0.27      0.22      0.24        18\n",
      "           5       0.40      0.44      0.42         9\n",
      "           6       0.32      0.38      0.34        16\n",
      "\n",
      "    accuracy                           0.34       107\n",
      "   macro avg       0.36      0.33      0.31       107\n",
      "weighted avg       0.35      0.34      0.31       107\n",
      "\n",
      "Accuracy: 0.3364, Precision: 0.3543, Recall: 0.3364, F1: 0.3125\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.50      0.32        18\n",
      "           1       0.43      0.30      0.35        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.22      0.14      0.17        14\n",
      "           4       0.29      0.22      0.25        18\n",
      "           5       0.36      0.44      0.40         9\n",
      "           6       0.22      0.25      0.24        16\n",
      "\n",
      "    accuracy                           0.27       107\n",
      "   macro avg       0.25      0.27      0.25       107\n",
      "weighted avg       0.26      0.27      0.25       107\n",
      "\n",
      "Accuracy: 0.2710, Precision: 0.2599, Recall: 0.2710, F1: 0.2527\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.78      0.35        18\n",
      "           1       0.39      0.45      0.42        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.27      0.33      0.30         9\n",
      "           6       0.25      0.12      0.17        16\n",
      "\n",
      "    accuracy                           0.26       107\n",
      "   macro avg       0.16      0.24      0.18       107\n",
      "weighted avg       0.17      0.26      0.19       107\n",
      "\n",
      "Accuracy: 0.2617, Precision: 0.1714, Recall: 0.2617, F1: 0.1873\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.56      0.32        18\n",
      "           1       0.56      0.45      0.50        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.20      0.21      0.21        14\n",
      "           4       0.40      0.11      0.17        18\n",
      "           5       0.29      0.44      0.35         9\n",
      "           6       0.42      0.31      0.36        16\n",
      "\n",
      "    accuracy                           0.31       107\n",
      "   macro avg       0.30      0.30      0.27       107\n",
      "weighted avg       0.32      0.31      0.29       107\n",
      "\n",
      "Accuracy: 0.3084, Precision: 0.3232, Recall: 0.3084, F1: 0.2867\n",
      "\n",
      "Running for n_segments = 10\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 10)\n",
      "\n",
      "--- GVV with 10 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.89      0.42        18\n",
      "           1       0.38      0.50      0.43        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.75      0.17      0.27        18\n",
      "           5       0.57      0.44      0.50         9\n",
      "           6       0.27      0.19      0.22        16\n",
      "\n",
      "    accuracy                           0.34       107\n",
      "   macro avg       0.32      0.31      0.26       107\n",
      "weighted avg       0.33      0.34      0.27       107\n",
      "\n",
      "Accuracy: 0.3364, Precision: 0.3333, Recall: 0.3364, F1: 0.2733\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.89      0.53        18\n",
      "           1       0.50      0.35      0.41        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.18      0.14      0.16        14\n",
      "           4       0.33      0.17      0.22        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.33      0.38      0.35        16\n",
      "\n",
      "    accuracy                           0.38       107\n",
      "   macro avg       0.33      0.39      0.34       107\n",
      "weighted avg       0.34      0.38      0.33       107\n",
      "\n",
      "Accuracy: 0.3832, Precision: 0.3363, Recall: 0.3832, F1: 0.3339\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.67      0.48        18\n",
      "           1       0.50      0.40      0.44        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.32      0.43      0.36        14\n",
      "           4       0.38      0.28      0.32        18\n",
      "           5       0.56      0.56      0.56         9\n",
      "           6       0.43      0.38      0.40        16\n",
      "\n",
      "    accuracy                           0.39       107\n",
      "   macro avg       0.37      0.39      0.37       107\n",
      "weighted avg       0.37      0.39      0.37       107\n",
      "\n",
      "Accuracy: 0.3925, Precision: 0.3734, Recall: 0.3925, F1: 0.3722\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.83      0.44        18\n",
      "           1       0.50      0.45      0.47        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.42      0.28      0.33        18\n",
      "           5       0.44      0.44      0.44         9\n",
      "           6       0.36      0.25      0.30        16\n",
      "\n",
      "    accuracy                           0.35       107\n",
      "   macro avg       0.29      0.32      0.28       107\n",
      "weighted avg       0.31      0.35      0.30       107\n",
      "\n",
      "Accuracy: 0.3458, Precision: 0.3058, Recall: 0.3458, F1: 0.3005\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.67      0.44        18\n",
      "           1       0.36      0.45      0.40        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.14      0.07      0.10        14\n",
      "           4       0.22      0.11      0.15        18\n",
      "           5       0.57      0.44      0.50         9\n",
      "           6       0.19      0.19      0.19        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.26      0.28      0.25       107\n",
      "weighted avg       0.25      0.29      0.26       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.2540, Recall: 0.2897, F1: 0.2556\n",
      "\n",
      "Running for n_segments = 15\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 15)\n",
      "\n",
      "--- GVV with 15 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.94      0.45        18\n",
      "           1       0.47      0.45      0.46        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.50      0.06      0.10        18\n",
      "           5       0.44      0.44      0.44         9\n",
      "           6       0.40      0.38      0.39        16\n",
      "\n",
      "    accuracy                           0.35       107\n",
      "   macro avg       0.30      0.32      0.26       107\n",
      "weighted avg       0.32      0.35      0.27       107\n",
      "\n",
      "Accuracy: 0.3458, Precision: 0.3200, Recall: 0.3458, F1: 0.2746\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.94      0.49        18\n",
      "           1       0.42      0.40      0.41        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.14      0.22        14\n",
      "           4       0.25      0.06      0.09        18\n",
      "           5       0.54      0.78      0.64         9\n",
      "           6       0.33      0.31      0.32        16\n",
      "\n",
      "    accuracy                           0.37       107\n",
      "   macro avg       0.34      0.38      0.31       107\n",
      "weighted avg       0.34      0.37      0.30       107\n",
      "\n",
      "Accuracy: 0.3738, Precision: 0.3363, Recall: 0.3738, F1: 0.3045\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.78      0.50        18\n",
      "           1       0.43      0.30      0.35        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.33      0.29      0.31        14\n",
      "           4       0.17      0.11      0.13        18\n",
      "           5       0.70      0.78      0.74         9\n",
      "           6       0.33      0.31      0.32        16\n",
      "\n",
      "    accuracy                           0.36       107\n",
      "   macro avg       0.33      0.37      0.34       107\n",
      "weighted avg       0.32      0.36      0.32       107\n",
      "\n",
      "Accuracy: 0.3551, Precision: 0.3225, Recall: 0.3551, F1: 0.3230\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.78      0.46        18\n",
      "           1       0.56      0.45      0.50        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.27      0.21      0.24        14\n",
      "           4       0.56      0.28      0.37        18\n",
      "           5       0.60      0.67      0.63         9\n",
      "           6       0.33      0.38      0.35        16\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.38      0.39      0.36       107\n",
      "weighted avg       0.39      0.40      0.37       107\n",
      "\n",
      "Accuracy: 0.4019, Precision: 0.3894, Recall: 0.4019, F1: 0.3703\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.72      0.49        18\n",
      "           1       0.32      0.35      0.33        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.25      0.14      0.18        14\n",
      "           4       0.22      0.11      0.15        18\n",
      "           5       0.29      0.44      0.35         9\n",
      "           6       0.38      0.38      0.38        16\n",
      "\n",
      "    accuracy                           0.32       107\n",
      "   macro avg       0.26      0.31      0.27       107\n",
      "weighted avg       0.27      0.32      0.28       107\n",
      "\n",
      "Accuracy: 0.3178, Precision: 0.2722, Recall: 0.3178, F1: 0.2789\n",
      "\n",
      "Running for n_segments = 20\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 20)\n",
      "\n",
      "--- GVV with 20 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.72      0.41        18\n",
      "           1       0.45      0.45      0.45        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.43      0.21      0.29        14\n",
      "           4       0.67      0.22      0.33        18\n",
      "           5       0.46      0.67      0.55         9\n",
      "           6       0.25      0.19      0.21        16\n",
      "\n",
      "    accuracy                           0.36       107\n",
      "   macro avg       0.36      0.35      0.32       107\n",
      "weighted avg       0.38      0.36      0.32       107\n",
      "\n",
      "Accuracy: 0.3551, Precision: 0.3761, Recall: 0.3551, F1: 0.3238\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.83      0.41        18\n",
      "           1       0.36      0.20      0.26        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.17      0.07      0.10        14\n",
      "           4       0.12      0.06      0.08        18\n",
      "           5       0.58      0.78      0.67         9\n",
      "           6       0.29      0.25      0.27        16\n",
      "\n",
      "    accuracy                           0.30       107\n",
      "   macro avg       0.26      0.31      0.25       107\n",
      "weighted avg       0.25      0.30      0.24       107\n",
      "\n",
      "Accuracy: 0.2991, Precision: 0.2477, Recall: 0.2991, F1: 0.2384\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.67      0.43        18\n",
      "           1       0.18      0.10      0.13        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.09      0.07      0.08        14\n",
      "           4       0.33      0.28      0.30        18\n",
      "           5       0.70      0.78      0.74         9\n",
      "           6       0.28      0.31      0.29        16\n",
      "\n",
      "    accuracy                           0.30       107\n",
      "   macro avg       0.27      0.32      0.28       107\n",
      "weighted avg       0.26      0.30      0.26       107\n",
      "\n",
      "Accuracy: 0.2991, Precision: 0.2555, Recall: 0.2991, F1: 0.2636\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.61      0.37        18\n",
      "           1       0.50      0.45      0.47        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.14      0.07      0.10        14\n",
      "           4       0.45      0.28      0.34        18\n",
      "           5       0.67      0.67      0.67         9\n",
      "           6       0.22      0.25      0.24        16\n",
      "\n",
      "    accuracy                           0.34       107\n",
      "   macro avg       0.32      0.33      0.31       107\n",
      "weighted avg       0.32      0.34      0.31       107\n",
      "\n",
      "Accuracy: 0.3364, Precision: 0.3231, Recall: 0.3364, F1: 0.3130\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42        18\n",
      "           1       0.32      0.45      0.38        20\n",
      "           2       0.50      0.17      0.25        12\n",
      "           3       0.12      0.07      0.09        14\n",
      "           4       0.12      0.06      0.08        18\n",
      "           5       0.40      0.44      0.42         9\n",
      "           6       0.21      0.25      0.23        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.29      0.28      0.27       107\n",
      "weighted avg       0.27      0.29      0.26       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.2747, Recall: 0.2897, F1: 0.2627\n",
      "\n",
      "Running for n_segments = 25\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 25)\n",
      "\n",
      "--- GVV with 25 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.72      0.44        18\n",
      "           1       0.37      0.50      0.43        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.17      0.07      0.10        14\n",
      "           4       0.57      0.22      0.32        18\n",
      "           5       0.44      0.44      0.44         9\n",
      "           6       0.23      0.19      0.21        16\n",
      "\n",
      "    accuracy                           0.33       107\n",
      "   macro avg       0.30      0.31      0.28       107\n",
      "weighted avg       0.31      0.33      0.29       107\n",
      "\n",
      "Accuracy: 0.3271, Precision: 0.3124, Recall: 0.3271, F1: 0.2889\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.89      0.45        18\n",
      "           1       0.45      0.25      0.32        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.25      0.07      0.11        14\n",
      "           4       0.10      0.06      0.07        18\n",
      "           5       0.53      0.89      0.67         9\n",
      "           6       0.36      0.31      0.33        16\n",
      "\n",
      "    accuracy                           0.34       107\n",
      "   macro avg       0.29      0.35      0.28       107\n",
      "weighted avg       0.28      0.34      0.27       107\n",
      "\n",
      "Accuracy: 0.3364, Precision: 0.2835, Recall: 0.3364, F1: 0.2686\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.56      0.42        18\n",
      "           1       0.50      0.35      0.41        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.27      0.29      0.28        14\n",
      "           4       0.22      0.22      0.22        18\n",
      "           5       0.60      0.67      0.63         9\n",
      "           6       0.25      0.25      0.25        16\n",
      "\n",
      "    accuracy                           0.33       107\n",
      "   macro avg       0.31      0.33      0.32       107\n",
      "weighted avg       0.31      0.33      0.31       107\n",
      "\n",
      "Accuracy: 0.3271, Precision: 0.3097, Recall: 0.3271, F1: 0.3110\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.67      0.42        18\n",
      "           1       0.47      0.40      0.43        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.18      0.14      0.16        14\n",
      "           4       0.18      0.11      0.14        18\n",
      "           5       0.62      0.56      0.59         9\n",
      "           6       0.22      0.25      0.24        16\n",
      "\n",
      "    accuracy                           0.32       107\n",
      "   macro avg       0.33      0.32      0.30       107\n",
      "weighted avg       0.32      0.32      0.30       107\n",
      "\n",
      "Accuracy: 0.3178, Precision: 0.3173, Recall: 0.3178, F1: 0.2954\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.61      0.42        18\n",
      "           1       0.28      0.35      0.31        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.29      0.14      0.19        14\n",
      "           4       0.40      0.11      0.17        18\n",
      "           5       0.20      0.22      0.21         9\n",
      "           6       0.19      0.25      0.22        16\n",
      "\n",
      "    accuracy                           0.26       107\n",
      "   macro avg       0.24      0.24      0.22       107\n",
      "weighted avg       0.26      0.26      0.23       107\n",
      "\n",
      "Accuracy: 0.2617, Precision: 0.2552, Recall: 0.2617, F1: 0.2322\n",
      "\n",
      "Running for n_segments = 30\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 30)\n",
      "\n",
      "--- GVV with 30 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.72      0.46        18\n",
      "           1       0.38      0.50      0.43        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.38      0.21      0.27        14\n",
      "           4       0.33      0.17      0.22        18\n",
      "           5       0.38      0.56      0.45         9\n",
      "           6       0.25      0.12      0.17        16\n",
      "\n",
      "    accuracy                           0.35       107\n",
      "   macro avg       0.33      0.34      0.30       107\n",
      "weighted avg       0.33      0.35      0.31       107\n",
      "\n",
      "Accuracy: 0.3458, Precision: 0.3309, Recall: 0.3458, F1: 0.3082\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.78      0.36        18\n",
      "           1       0.45      0.25      0.32        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.40      0.11      0.17        18\n",
      "           5       0.60      1.00      0.75         9\n",
      "           6       0.33      0.25      0.29        16\n",
      "\n",
      "    accuracy                           0.32       107\n",
      "   macro avg       0.29      0.34      0.27       107\n",
      "weighted avg       0.29      0.32      0.26       107\n",
      "\n",
      "Accuracy: 0.3178, Precision: 0.2925, Recall: 0.3178, F1: 0.2565\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.89      0.53        18\n",
      "           1       0.29      0.20      0.24        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.30      0.21      0.25        14\n",
      "           4       0.09      0.06      0.07        18\n",
      "           5       0.67      0.89      0.76         9\n",
      "           6       0.27      0.25      0.26        16\n",
      "\n",
      "    accuracy                           0.34       107\n",
      "   macro avg       0.28      0.36      0.30       107\n",
      "weighted avg       0.27      0.34      0.28       107\n",
      "\n",
      "Accuracy: 0.3364, Precision: 0.2680, Recall: 0.3364, F1: 0.2807\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.89      0.53        18\n",
      "           1       0.29      0.35      0.32        20\n",
      "           2       0.50      0.17      0.25        12\n",
      "           3       0.17      0.07      0.10        14\n",
      "           4       0.50      0.22      0.31        18\n",
      "           5       0.67      0.67      0.67         9\n",
      "           6       0.21      0.19      0.20        16\n",
      "\n",
      "    accuracy                           0.36       107\n",
      "   macro avg       0.39      0.36      0.34       107\n",
      "weighted avg       0.37      0.36      0.33       107\n",
      "\n",
      "Accuracy: 0.3645, Precision: 0.3687, Recall: 0.3645, F1: 0.3281\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34        18\n",
      "           1       0.38      0.50      0.43        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.12      0.07      0.09        14\n",
      "           4       0.00      0.00      0.00        18\n",
      "           5       0.31      0.44      0.36         9\n",
      "           6       0.29      0.25      0.27        16\n",
      "\n",
      "    accuracy                           0.27       107\n",
      "   macro avg       0.19      0.26      0.21       107\n",
      "weighted avg       0.20      0.27      0.22       107\n",
      "\n",
      "Accuracy: 0.2710, Precision: 0.1979, Recall: 0.2710, F1: 0.2206\n",
      "\n",
      "Running for n_segments = 35\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 35)\n",
      "\n",
      "--- GVV with 35 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.61      0.38        18\n",
      "           1       0.50      0.30      0.38        20\n",
      "           2       0.67      0.17      0.27        12\n",
      "           3       0.20      0.21      0.21        14\n",
      "           4       0.50      0.28      0.36        18\n",
      "           5       0.56      0.56      0.56         9\n",
      "           6       0.28      0.31      0.29        16\n",
      "\n",
      "    accuracy                           0.35       107\n",
      "   macro avg       0.42      0.35      0.35       107\n",
      "weighted avg       0.41      0.35      0.34       107\n",
      "\n",
      "Accuracy: 0.3458, Precision: 0.4130, Recall: 0.3458, F1: 0.3417\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.61      0.33        18\n",
      "           1       0.40      0.20      0.27        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.25      0.14      0.18        14\n",
      "           4       0.14      0.06      0.08        18\n",
      "           5       0.60      1.00      0.75         9\n",
      "           6       0.21      0.25      0.23        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.26      0.32      0.26       107\n",
      "weighted avg       0.25      0.29      0.24       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.2520, Recall: 0.2897, F1: 0.2404\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.61      0.38        18\n",
      "           1       0.25      0.15      0.19        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.21      0.21      0.21        14\n",
      "           4       0.30      0.17      0.21        18\n",
      "           5       0.70      0.78      0.74         9\n",
      "           6       0.26      0.31      0.29        16\n",
      "\n",
      "    accuracy                           0.31       107\n",
      "   macro avg       0.36      0.33      0.31       107\n",
      "weighted avg       0.33      0.31      0.28       107\n",
      "\n",
      "Accuracy: 0.3084, Precision: 0.3258, Recall: 0.3084, F1: 0.2837\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.83      0.49        18\n",
      "           1       0.33      0.30      0.32        20\n",
      "           2       0.67      0.17      0.27        12\n",
      "           3       0.17      0.14      0.15        14\n",
      "           4       0.50      0.22      0.31        18\n",
      "           5       0.75      0.67      0.71         9\n",
      "           6       0.27      0.25      0.26        16\n",
      "\n",
      "    accuracy                           0.36       107\n",
      "   macro avg       0.43      0.37      0.36       107\n",
      "weighted avg       0.40      0.36      0.34       107\n",
      "\n",
      "Accuracy: 0.3645, Precision: 0.4046, Recall: 0.3645, F1: 0.3415\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.50      0.37        18\n",
      "           1       0.30      0.40      0.34        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.29      0.11      0.16        18\n",
      "           5       0.29      0.44      0.35         9\n",
      "           6       0.31      0.31      0.31        16\n",
      "\n",
      "    accuracy                           0.27       107\n",
      "   macro avg       0.25      0.26      0.24       107\n",
      "weighted avg       0.25      0.27      0.24       107\n",
      "\n",
      "Accuracy: 0.2710, Precision: 0.2511, Recall: 0.2710, F1: 0.2423\n",
      "\n",
      "Running for n_segments = 40\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 40)\n",
      "\n",
      "--- GVV with 40 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.61      0.42        18\n",
      "           1       0.35      0.30      0.32        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.07      0.07      0.07        14\n",
      "           4       0.33      0.28      0.30        18\n",
      "           5       0.44      0.44      0.44         9\n",
      "           6       0.29      0.25      0.27        16\n",
      "\n",
      "    accuracy                           0.30       107\n",
      "   macro avg       0.31      0.29      0.28       107\n",
      "weighted avg       0.30      0.30      0.28       107\n",
      "\n",
      "Accuracy: 0.2991, Precision: 0.3018, Recall: 0.2991, F1: 0.2830\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.72      0.37        18\n",
      "           1       0.20      0.05      0.08        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.50      0.14      0.22        14\n",
      "           4       0.18      0.11      0.14        18\n",
      "           5       0.53      1.00      0.69         9\n",
      "           6       0.29      0.31      0.30        16\n",
      "\n",
      "    accuracy                           0.30       107\n",
      "   macro avg       0.28      0.33      0.26       107\n",
      "weighted avg       0.26      0.30      0.23       107\n",
      "\n",
      "Accuracy: 0.2991, Precision: 0.2632, Recall: 0.2991, F1: 0.2324\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.67      0.45        18\n",
      "           1       0.47      0.35      0.40        20\n",
      "           2       0.50      0.08      0.14        12\n",
      "           3       0.30      0.50      0.38        14\n",
      "           4       0.14      0.11      0.12        18\n",
      "           5       0.45      0.56      0.50         9\n",
      "           6       0.43      0.19      0.26        16\n",
      "\n",
      "    accuracy                           0.35       107\n",
      "   macro avg       0.38      0.35      0.32       107\n",
      "weighted avg       0.37      0.35      0.32       107\n",
      "\n",
      "Accuracy: 0.3458, Precision: 0.3672, Recall: 0.3458, F1: 0.3186\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.56      0.43        18\n",
      "           1       0.44      0.35      0.39        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.07      0.07      0.07        14\n",
      "           4       0.40      0.33      0.36        18\n",
      "           5       0.60      0.67      0.63         9\n",
      "           6       0.15      0.19      0.17        16\n",
      "\n",
      "    accuracy                           0.31       107\n",
      "   macro avg       0.29      0.31      0.29       107\n",
      "weighted avg       0.29      0.31      0.29       107\n",
      "\n",
      "Accuracy: 0.3084, Precision: 0.2908, Recall: 0.3084, F1: 0.2941\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.56      0.40        18\n",
      "           1       0.28      0.35      0.31        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        14\n",
      "           4       0.40      0.11      0.17        18\n",
      "           5       0.20      0.33      0.25         9\n",
      "           6       0.27      0.25      0.26        16\n",
      "\n",
      "    accuracy                           0.24       107\n",
      "   macro avg       0.21      0.23      0.20       107\n",
      "weighted avg       0.23      0.24      0.21       107\n",
      "\n",
      "Accuracy: 0.2430, Precision: 0.2289, Recall: 0.2430, F1: 0.2143\n",
      "\n",
      "Running for n_segments = 45\n",
      "Number of files processed: 535\n",
      "GVV-only shape: (535, 45)\n",
      "\n",
      "--- GVV with 45 segments ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.67      0.44        18\n",
      "           1       0.36      0.25      0.29        20\n",
      "           2       0.20      0.08      0.12        12\n",
      "           3       0.20      0.14      0.17        14\n",
      "           4       0.25      0.22      0.24        18\n",
      "           5       0.38      0.33      0.35         9\n",
      "           6       0.29      0.31      0.30        16\n",
      "\n",
      "    accuracy                           0.30       107\n",
      "   macro avg       0.29      0.29      0.27       107\n",
      "weighted avg       0.29      0.30      0.28       107\n",
      "\n",
      "Accuracy: 0.2991, Precision: 0.2875, Recall: 0.2991, F1: 0.2780\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.89      0.44        18\n",
      "           1       0.53      0.40      0.46        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.20      0.07      0.11        14\n",
      "           4       0.40      0.11      0.17        18\n",
      "           5       0.44      0.78      0.56         9\n",
      "           6       0.33      0.25      0.29        16\n",
      "\n",
      "    accuracy                           0.36       107\n",
      "   macro avg       0.31      0.36      0.29       107\n",
      "weighted avg       0.33      0.36      0.29       107\n",
      "\n",
      "Accuracy: 0.3551, Precision: 0.3296, Recall: 0.3551, F1: 0.2931\n",
      "\n",
      "Training and evaluating: XGBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.56      0.36        18\n",
      "           1       0.29      0.20      0.24        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.09      0.07      0.08        14\n",
      "           4       0.43      0.33      0.38        18\n",
      "           5       0.47      0.78      0.58         9\n",
      "           6       0.23      0.19      0.21        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.25      0.30      0.26       107\n",
      "weighted avg       0.26      0.29      0.26       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.2566, Recall: 0.2897, F1: 0.2587\n",
      "\n",
      "Training and evaluating: LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.72      0.51        18\n",
      "           1       0.44      0.35      0.39        20\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.18      0.14      0.16        14\n",
      "           4       0.33      0.33      0.33        18\n",
      "           5       0.60      0.67      0.63         9\n",
      "           6       0.18      0.19      0.18        16\n",
      "\n",
      "    accuracy                           0.35       107\n",
      "   macro avg       0.30      0.34      0.32       107\n",
      "weighted avg       0.30      0.35      0.32       107\n",
      "\n",
      "Accuracy: 0.3458, Precision: 0.3048, Recall: 0.3458, F1: 0.3158\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.78      0.52        18\n",
      "           1       0.32      0.45      0.38        20\n",
      "           2       0.25      0.08      0.12        12\n",
      "           3       0.08      0.07      0.07        14\n",
      "           4       0.12      0.06      0.08        18\n",
      "           5       0.27      0.33      0.30         9\n",
      "           6       0.29      0.12      0.17        16\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.25      0.27      0.23       107\n",
      "weighted avg       0.25      0.29      0.25       107\n",
      "\n",
      "Accuracy: 0.2897, Precision: 0.2503, Recall: 0.2897, F1: 0.2452\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>▇▅█▅▃▄▄▁▅</td></tr><tr><td>KNN_F1</td><td>█▅▇▆▃▂▄▁▄</td></tr><tr><td>KNN_Precision</td><td>█▄▅▅▄▁▄▃▄</td></tr><tr><td>KNN_Recall</td><td>▇▅█▅▃▄▄▁▅</td></tr><tr><td>LogisticRegression_Accuracy</td><td>▁▅█▅▄▆▆▃▅</td></tr><tr><td>LogisticRegression_F1</td><td>▁▅█▆▅▆▇▅▆</td></tr><tr><td>LogisticRegression_Precision</td><td>▁▅█▆▅▇█▅▅</td></tr><tr><td>LogisticRegression_Recall</td><td>▁▅█▅▄▆▆▃▅</td></tr><tr><td>RandomForest_Accuracy</td><td>▅█▇▂▅▃▁▂▆</td></tr><tr><td>RandomForest_F1</td><td>▇█▆▁▃▃▂▁▅</td></tr><tr><td>RandomForest_Precision</td><td>█▇▇▁▃▄▁▂▆</td></tr><tr><td>RandomForest_Recall</td><td>▅█▇▂▅▃▁▂▆</td></tr><tr><td>SVM_Accuracy</td><td>▁▆▇█▅▇▇▂▂</td></tr><tr><td>SVM_F1</td><td>▁▅▅▇▅▆█▅▅</td></tr><tr><td>SVM_Precision</td><td>▁▅▅▇▄▅█▄▃</td></tr><tr><td>SVM_Recall</td><td>▁▆▇█▅▇▇▂▂</td></tr><tr><td>XGBoost_Accuracy</td><td>▁█▆▃▄▅▃▅▂</td></tr><tr><td>XGBoost_F1</td><td>▁█▅▂▄▃▃▅▁</td></tr><tr><td>XGBoost_Precision</td><td>▁█▅▁▄▂▅█▁</td></tr><tr><td>XGBoost_Recall</td><td>▁█▆▃▄▅▃▅▂</td></tr><tr><td>feature_dim</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>gvv_segments</td><td>▁▂▃▄▅▅▆▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GVV_n10_best_accuracy</td><td>0.39252</td></tr><tr><td>GVV_n15_best_accuracy</td><td>0.40187</td></tr><tr><td>GVV_n20_best_accuracy</td><td>0.35514</td></tr><tr><td>GVV_n25_best_accuracy</td><td>0.33645</td></tr><tr><td>GVV_n30_best_accuracy</td><td>0.36449</td></tr><tr><td>GVV_n35_best_accuracy</td><td>0.36449</td></tr><tr><td>GVV_n40_best_accuracy</td><td>0.34579</td></tr><tr><td>GVV_n45_best_accuracy</td><td>0.35514</td></tr><tr><td>GVV_n5_best_accuracy</td><td>0.33645</td></tr><tr><td>KNN_Accuracy</td><td>0.28972</td></tr><tr><td>KNN_F1</td><td>0.24521</td></tr><tr><td>KNN_Precision</td><td>0.25029</td></tr><tr><td>KNN_Recall</td><td>0.28972</td></tr><tr><td>LogisticRegression_Accuracy</td><td>0.34579</td></tr><tr><td>LogisticRegression_F1</td><td>0.31577</td></tr><tr><td>LogisticRegression_Precision</td><td>0.30477</td></tr><tr><td>LogisticRegression_Recall</td><td>0.34579</td></tr><tr><td>RandomForest_Accuracy</td><td>0.35514</td></tr><tr><td>RandomForest_F1</td><td>0.29307</td></tr><tr><td>RandomForest_Precision</td><td>0.32963</td></tr><tr><td>RandomForest_Recall</td><td>0.35514</td></tr><tr><td>SVM_Accuracy</td><td>0.29907</td></tr><tr><td>SVM_F1</td><td>0.27796</td></tr><tr><td>SVM_Precision</td><td>0.28749</td></tr><tr><td>SVM_Recall</td><td>0.29907</td></tr><tr><td>XGBoost_Accuracy</td><td>0.28972</td></tr><tr><td>XGBoost_F1</td><td>0.25871</td></tr><tr><td>XGBoost_Precision</td><td>0.25662</td></tr><tr><td>XGBoost_Recall</td><td>0.28972</td></tr><tr><td>feature_dim</td><td>45</td></tr><tr><td>feature_type</td><td>GVV</td></tr><tr><td>gvv_segments</td><td>45</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-gvv-classification</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/aix4js6v' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/aix4js6v</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_231606-aix4js6v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# Initialize wandb\n",
    "wandb.init(project=\"emotion-recognition\", name=\"ssp-gvv-classification\")\n",
    "\n",
    "# Experiment with different segment values for GVV features\n",
    "gvv_segment_values = np.arange(5, 100, 10)  # Try different segment values from 5 to 45\n",
    "labels = pd.read_csv(labels_csv_path)\n",
    "\n",
    "for n in gvv_segment_values:\n",
    "    print(f\"\\nRunning for n_segments = {n}\")\n",
    "    \n",
    "    # Extract GVV features with the current number of segments\n",
    "    features = process_directory_gvv(directory, n_segments=n)\n",
    "    print(f\"Number of files processed: {len(features)}\")\n",
    "    \n",
    "    # Prepare feature sets\n",
    "    X_gvv, y_gvv = [], []\n",
    "    for _, row in labels.iterrows():\n",
    "        file_id = row['Filename']\n",
    "        if file_id in features:\n",
    "            X_gvv.append(features[file_id])\n",
    "            y_gvv.append(int(row['EmotionNumeric']))\n",
    "    \n",
    "    X_gvv = np.array(X_gvv)\n",
    "    y_gvv = np.array(y_gvv)\n",
    "    \n",
    "    print(\"GVV-only shape:\", X_gvv.shape)\n",
    "    \n",
    "    # Train and evaluate classifiers, logging metrics to wandb\n",
    "    print(f\"\\n--- GVV with {n} segments ---\")\n",
    "    metrics = train_and_evaluate(X_gvv, y_gvv)\n",
    "    \n",
    "    # Log metrics to wandb with current segment value\n",
    "    log_data = {\n",
    "        \"gvv_segments\": n,\n",
    "        \"feature_type\": \"GVV\",\n",
    "        \"feature_dim\": X_gvv.shape[1],\n",
    "        **metrics\n",
    "    }\n",
    "    \n",
    "    wandb.log(log_data)\n",
    "    \n",
    "    # Add summary for easy comparison\n",
    "    wandb.run.summary[f\"GVV_n{n}_best_accuracy\"] = max([\n",
    "        metrics.get(\"SVM_Accuracy\", 0),\n",
    "        metrics.get(\"RandomForest_Accuracy\", 0),\n",
    "        metrics.get(\"XGBoost_Accuracy\", 0),\n",
    "        metrics.get(\"LogisticRegression_Accuracy\", 0),\n",
    "        metrics.get(\"KNN_Accuracy\", 0)\n",
    "    ])\n",
    "\n",
    "# Finish wandb run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\College\\4-2\\SSP\\SSP_Project\\newProject\\EmotionRecognition_SSP\\wandb\\run-20250421_231843-53efum7h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/53efum7h' target=\"_blank\">ssp-combined-features</a></strong> to <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/53efum7h' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/53efum7h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MFCC features...\n",
      "Extracting RCC features...\n",
      "Extracting LP features...\n",
      "Extracting GVV features...\n",
      "Feature counts: {'total': 535, 'mfcc_only': 535, 'rcc_only': 0, 'lp_only': 0, 'gvv_only': 0, 'combined': 535}\n",
      "Number of files with all features: 535\n",
      "Combined dataset shape: (535, 850)\n",
      "\n",
      "--- Combined Features Classification ---\n",
      "\n",
      "Training and evaluating: SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.72      0.63        18\n",
      "           1       0.50      0.40      0.44        20\n",
      "           2       0.11      0.08      0.10        12\n",
      "           3       0.60      0.64      0.62        14\n",
      "           4       0.57      0.44      0.50        18\n",
      "           5       0.50      0.67      0.57         9\n",
      "           6       0.50      0.56      0.53        16\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.48      0.50      0.49       107\n",
      "weighted avg       0.49      0.50      0.49       107\n",
      "\n",
      "Accuracy: 0.5047, Precision: 0.4925, Recall: 0.5047, F1: 0.4930\n",
      "\n",
      "Training and evaluating: RandomForest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.89      0.56        18\n",
      "           1       0.59      0.65      0.62        20\n",
      "           2       1.00      0.08      0.15        12\n",
      "           3       0.60      0.21      0.32        14\n",
      "           4       0.71      0.28      0.40        18\n",
      "           5       0.69      1.00      0.82         9\n",
      "           6       0.45      0.56      0.50        16\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.64      0.53      0.48       107\n",
      "weighted avg       0.62      0.52      0.48       107\n",
      "\n",
      "Accuracy: 0.5234, Precision: 0.6158, Recall: 0.5234, F1: 0.4796\n",
      "\n",
      "Training and evaluating: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.83      0.71        18\n",
      "           1       0.60      0.45      0.51        20\n",
      "           2       0.29      0.17      0.21        12\n",
      "           3       0.46      0.43      0.44        14\n",
      "           4       0.53      0.44      0.48        18\n",
      "           5       0.57      0.89      0.70         9\n",
      "           6       0.53      0.62      0.57        16\n",
      "\n",
      "    accuracy                           0.54       107\n",
      "   macro avg       0.51      0.55      0.52       107\n",
      "weighted avg       0.53      0.54      0.52       107\n",
      "\n",
      "Accuracy: 0.5421, Precision: 0.5262, Recall: 0.5421, F1: 0.5236\n",
      "\n",
      "Training and evaluating: LogisticRegression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.61      0.65        18\n",
      "           1       0.67      0.40      0.50        20\n",
      "           2       0.25      0.25      0.25        12\n",
      "           3       0.42      0.57      0.48        14\n",
      "           4       0.42      0.28      0.33        18\n",
      "           5       0.38      0.56      0.45         9\n",
      "           6       0.43      0.62      0.51        16\n",
      "\n",
      "    accuracy                           0.47       107\n",
      "   macro avg       0.47      0.47      0.45       107\n",
      "weighted avg       0.49      0.47      0.46       107\n",
      "\n",
      "Accuracy: 0.4673, Precision: 0.4909, Recall: 0.4673, F1: 0.4648\n",
      "\n",
      "Training and evaluating: KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.83      0.57        18\n",
      "           1       0.42      0.40      0.41        20\n",
      "           2       0.33      0.08      0.13        12\n",
      "           3       0.44      0.29      0.35        14\n",
      "           4       0.67      0.22      0.33        18\n",
      "           5       0.67      0.44      0.53         9\n",
      "           6       0.38      0.69      0.49        16\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.48      0.42      0.40       107\n",
      "weighted avg       0.47      0.44      0.41       107\n",
      "\n",
      "Accuracy: 0.4393, Precision: 0.4713, Recall: 0.4393, F1: 0.4064\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>KNN_Accuracy</td><td>▁</td></tr><tr><td>KNN_F1</td><td>▁</td></tr><tr><td>KNN_Precision</td><td>▁</td></tr><tr><td>KNN_Recall</td><td>▁</td></tr><tr><td>LogisticRegression_Accuracy</td><td>▁</td></tr><tr><td>LogisticRegression_F1</td><td>▁</td></tr><tr><td>LogisticRegression_Precision</td><td>▁</td></tr><tr><td>LogisticRegression_Recall</td><td>▁</td></tr><tr><td>RandomForest_Accuracy</td><td>▁</td></tr><tr><td>RandomForest_F1</td><td>▁</td></tr><tr><td>RandomForest_Precision</td><td>▁</td></tr><tr><td>RandomForest_Recall</td><td>▁</td></tr><tr><td>SVM_Accuracy</td><td>▁</td></tr><tr><td>SVM_F1</td><td>▁</td></tr><tr><td>SVM_Precision</td><td>▁</td></tr><tr><td>SVM_Recall</td><td>▁</td></tr><tr><td>XGBoost_Accuracy</td><td>▁</td></tr><tr><td>XGBoost_F1</td><td>▁</td></tr><tr><td>XGBoost_Precision</td><td>▁</td></tr><tr><td>XGBoost_Recall</td><td>▁</td></tr><tr><td>dataset_size</td><td>▁</td></tr><tr><td>gvv_dim</td><td>▁</td></tr><tr><td>lp_dim</td><td>▁</td></tr><tr><td>mfcc_dim</td><td>▁</td></tr><tr><td>rcc_dim</td><td>▁</td></tr><tr><td>total_dim</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Combined_best_accuracy</td><td>0.54206</td></tr><tr><td>KNN_Accuracy</td><td>0.43925</td></tr><tr><td>KNN_F1</td><td>0.40641</td></tr><tr><td>KNN_Precision</td><td>0.47128</td></tr><tr><td>KNN_Recall</td><td>0.43925</td></tr><tr><td>LogisticRegression_Accuracy</td><td>0.46729</td></tr><tr><td>LogisticRegression_F1</td><td>0.46478</td></tr><tr><td>LogisticRegression_Precision</td><td>0.49085</td></tr><tr><td>LogisticRegression_Recall</td><td>0.46729</td></tr><tr><td>RandomForest_Accuracy</td><td>0.52336</td></tr><tr><td>RandomForest_F1</td><td>0.4796</td></tr><tr><td>RandomForest_Precision</td><td>0.6158</td></tr><tr><td>RandomForest_Recall</td><td>0.52336</td></tr><tr><td>SVM_Accuracy</td><td>0.50467</td></tr><tr><td>SVM_F1</td><td>0.49299</td></tr><tr><td>SVM_Precision</td><td>0.49246</td></tr><tr><td>SVM_Recall</td><td>0.50467</td></tr><tr><td>XGBoost_Accuracy</td><td>0.54206</td></tr><tr><td>XGBoost_F1</td><td>0.52357</td></tr><tr><td>XGBoost_Precision</td><td>0.52621</td></tr><tr><td>XGBoost_Recall</td><td>0.54206</td></tr><tr><td>dataset_size</td><td>535</td></tr><tr><td>feature_type</td><td>Combined</td></tr><tr><td>gvv_dim</td><td>25</td></tr><tr><td>lp_dim</td><td>60</td></tr><tr><td>mfcc_dim</td><td>585</td></tr><tr><td>rcc_dim</td><td>180</td></tr><tr><td>total_dim</td><td>850</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ssp-combined-features</strong> at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition/runs/53efum7h' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition/runs/53efum7h</a><br> View project at: <a href='https://wandb.ai/its_mrpsycho/emotion-recognition' target=\"_blank\">https://wandb.ai/its_mrpsycho/emotion-recognition</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250421_231843-53efum7h\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import wandb\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# # Initialize wandb\n",
    "# wandb.init(project=\"emotion-recognition\", name=\"ssp-combined-features\")\n",
    "\n",
    "# # Define best parameter settings for each feature type based on previous experiments\n",
    "# mfcc_segments = 15  # Adjust based on your best MFCC results\n",
    "# rcc_segments = 15   # Adjust based on your best RCC results\n",
    "# lp_segments = 60    # Adjust based on your best LP results\n",
    "# gvv_segments = 25   # Adjust based on your best GVV results\n",
    "\n",
    "# labels = pd.read_csv(labels_csv_path)\n",
    "\n",
    "# # Extract features with the optimal segment values\n",
    "# print(\"Extracting MFCC features...\")\n",
    "# mfcc_features = process_directory_mfcc(directory, n_segments=mfcc_segments)\n",
    "\n",
    "# print(\"Extracting RCC features...\")\n",
    "# rcc_features = process_directory_rcc(directory, target_rcc_segments=rcc_segments)\n",
    "\n",
    "# print(\"Extracting LP features...\")\n",
    "# lp_features = process_directory_lp(directory, target_lp_segments=lp_segments)\n",
    "\n",
    "# print(\"Extracting GVV features...\")\n",
    "# gvv_features = process_directory_gvv(directory, n_segments=gvv_segments)\n",
    "\n",
    "# # Combine features by concatenation\n",
    "# combined_features = {}\n",
    "# feature_counts = {\n",
    "#     'total': 0,\n",
    "#     'mfcc_only': 0,\n",
    "#     'rcc_only': 0,\n",
    "#     'lp_only': 0,\n",
    "#     'gvv_only': 0,\n",
    "#     'combined': 0\n",
    "# }\n",
    "\n",
    "# for filename in os.listdir(directory):\n",
    "#     if filename.endswith('.wav'):\n",
    "#         feature_counts['total'] += 1\n",
    "        \n",
    "#         # For each file, collect available features\n",
    "#         vectors = []\n",
    "        \n",
    "#         if filename in mfcc_features:\n",
    "#             mfcc_vec = mfcc_features[filename].flatten()\n",
    "#             vectors.append(mfcc_vec)\n",
    "#             if len(vectors) == 1:\n",
    "#                 feature_counts['mfcc_only'] += 1\n",
    "        \n",
    "#         if filename in rcc_features:\n",
    "#             rcc_vec = rcc_features[filename]  # Already flattened\n",
    "#             vectors.append(rcc_vec)\n",
    "#             if len(vectors) == 1:\n",
    "#                 feature_counts['rcc_only'] += 1\n",
    "        \n",
    "#         if filename in lp_features:\n",
    "#             lp_vec = lp_features[filename]  # Already flattened\n",
    "#             vectors.append(lp_vec)\n",
    "#             if len(vectors) == 1:\n",
    "#                 feature_counts['lp_only'] += 1\n",
    "        \n",
    "#         if filename in gvv_features:\n",
    "#             gvv_vec = gvv_features[filename]  # Already flattened\n",
    "#             vectors.append(gvv_vec)\n",
    "#             if len(vectors) == 1:\n",
    "#                 feature_counts['gvv_only'] += 1\n",
    "        \n",
    "#         # Only include files that have all feature types\n",
    "#         if len(vectors) == 4:  # All feature types available\n",
    "#             combined = np.concatenate(vectors)\n",
    "#             combined_features[filename] = combined\n",
    "#             feature_counts['combined'] += 1\n",
    "\n",
    "# print(f\"Feature counts: {feature_counts}\")\n",
    "# print(f\"Number of files with all features: {len(combined_features)}\")\n",
    "\n",
    "# # Prepare dataset using the combined feature vectors\n",
    "# X_combined, y_combined = [], []\n",
    "# for _, row in labels.iterrows():\n",
    "#     file_id = row['Filename']\n",
    "#     if file_id in combined_features:\n",
    "#         X_combined.append(combined_features[file_id])\n",
    "#         y_combined.append(int(row['EmotionNumeric']))\n",
    "\n",
    "# X_combined = np.array(X_combined)\n",
    "# y_combined = np.array(y_combined)\n",
    "\n",
    "# print(\"Combined dataset shape:\", X_combined.shape)\n",
    "\n",
    "# # Train and evaluate classifiers on the combined feature set\n",
    "# print(\"\\n--- Combined Features Classification ---\")\n",
    "# metrics = train_and_evaluate(X_combined, y_combined)\n",
    "\n",
    "# # Log metrics to wandb\n",
    "# feature_dimensions = {\n",
    "#     'mfcc_dim': mfcc_segments * 39,\n",
    "#     'rcc_dim': rcc_segments * 12,\n",
    "#     'lp_dim': lp_segments,\n",
    "#     'gvv_dim': gvv_segments,\n",
    "#     'total_dim': X_combined.shape[1]\n",
    "# }\n",
    "\n",
    "# log_data = {\n",
    "#     'feature_type': 'Combined',\n",
    "#     **feature_dimensions,\n",
    "#     'dataset_size': len(X_combined),\n",
    "#     **metrics\n",
    "# }\n",
    "\n",
    "# wandb.log(log_data)\n",
    "\n",
    "# # Add summary for easy comparison\n",
    "# wandb.run.summary[\"Combined_best_accuracy\"] = max([\n",
    "#     metrics.get(\"SVM_Accuracy\", 0),\n",
    "#     metrics.get(\"RandomForest_Accuracy\", 0),\n",
    "#     metrics.get(\"XGBoost_Accuracy\", 0),\n",
    "#     metrics.get(\"LogisticRegression_Accuracy\", 0),\n",
    "#     metrics.get(\"KNN_Accuracy\", 0)\n",
    "# ])\n",
    "\n",
    "# # Finish wandb run\n",
    "# wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
